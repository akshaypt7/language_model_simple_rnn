{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshaypt7/language_model_simple_rnn/blob/main/AI3_HW1_Language_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c28bSQkcLRKn"
      },
      "source": [
        "# Language Models\n",
        "## Homework 1: Language Modeling\n",
        "\n",
        "**Instructor**: Pavlos Protopapas<br />\n",
        "**Maximum Score**: 70\n",
        "\n",
        "<hr style=\"height:2pt\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inKAshSLL7U1"
      },
      "source": [
        "\n",
        "## INSTRUCTIONS\n",
        "\n",
        "- This homework is a notebook. Download and work on it on your local machine or work on it in Colab.\n",
        "\n",
        "- This homework should be submitted in pairs.\n",
        "\n",
        "- Ensure you and your partner together have submitted the homework only once. Multiple submissions of the same work will be penalised and will cost you 2 points.\n",
        "\n",
        "- Please restart the kernel and run the entire notebook again before you submit.\n",
        "\n",
        "- Running cells out of order is a common pitfall in Jupyter Notebooks. To make sure your code works restart the kernel and run the whole notebook again before you submit. \n",
        "\n",
        "- To submit the homework, either one of you upload the working notebook on edStem and click the submit button on the bottom right corner.\n",
        "\n",
        "- Submit the homework well before the given deadline. Submissions after the deadline will not be graded.\n",
        "\n",
        "- We have tried to include all the libraries you may need to do the assignment in the imports statement at the top of this notebook. We strongly suggest that you use those and not others as we may not be familiar with them.\n",
        "\n",
        "- Comment your code well. This would help the graders in case there is any issue with the notebook while running. It is important to remember that the graders will not troubleshoot your code. \n",
        "\n",
        "- Please use .head() when viewing data. Do not submit a notebook that is **excessively long**. \n",
        "\n",
        "- In questions that require code to answer, such as \"calculate the $R^2$\", do not just output the value from a cell. Write a `print()` function that includes a reference to the calculated value, **not hardcoded**. For example: \n",
        "```\n",
        "print(f'The R^2 is {R:.4f}')\n",
        "```\n",
        "- Your plots should include clear labels for the $x$ and $y$ axes as well as a descriptive title (\"MSE plot\" is not a descriptive title; \"95 % confidence interval of coefficients of polynomial degree 5\" is).\n",
        "\n",
        "- **Ensure you make appropriate plots for all the questions it is applicable to, regardless of it being explicitly asked for.**\n",
        "\n",
        "<hr style=\"height:2pt\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDJ0FICOrxoy"
      },
      "source": [
        "## **Names of the people who worked on this homework together**\n",
        "#### / Names here/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkQ9H3dgXimi"
      },
      "source": [
        "## **HOMEWORK QUIZ**\n",
        "\n",
        "**For each part of the homework, there is an associated quiz on edStem. You are required to attempt that after completing each section of this homework.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2p5Wx_BMPUu"
      },
      "source": [
        "## **Setup Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gOe-gtbMVD5"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8F79dR16Im-",
        "outputId": "35b1d88f-944e-43e1-e64e-1e658c433b54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWsstoz5KnwW",
        "outputId": "e061d29d-73f3-4338-c554-5bcd841099af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import re\n",
        "import os\n",
        "import zipfile\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "%matplotlib inline\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from collections import defaultdict\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "nltk.download('punkt')\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.models import Model, Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCKMuo0TM5dH"
      },
      "source": [
        "**Verify Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5Eh4YpOQTlW",
        "outputId": "72a2e207-3218-45c8-8d4a-ff962f8c2055"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow version 2.8.0\n",
            "keras version 2.8.0\n",
            "Eager Execution Enabled: True\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "Number of replicas: 1\n",
            "Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
            "GPU Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "All Physical Devices [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "# Enable/Disable Eager Execution\n",
        "# Reference: https://www.tensorflow.org/guide/eager\n",
        "# TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, \n",
        "# without building graphs\n",
        "\n",
        "#tf.compat.v1.disable_eager_execution()\n",
        "#tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "print(\"tensorflow version\", tf.__version__)\n",
        "print(\"keras version\", tf.keras.__version__)\n",
        "print(\"Eager Execution Enabled:\", tf.executing_eagerly())\n",
        "\n",
        "# Get the number of replicas \n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print(\"Number of replicas:\", strategy.num_replicas_in_sync)\n",
        "\n",
        "devices = tf.config.experimental.get_visible_devices()\n",
        "print(\"Devices:\", devices)\n",
        "print(tf.config.experimental.list_logical_devices('GPU'))\n",
        "\n",
        "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
        "print(\"All Physical Devices\", tf.config.list_physical_devices())\n",
        "\n",
        "# Better performance with the tf.data API\n",
        "# Reference: https://www.tensorflow.org/guide/data_performance\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kAR4k4uHXkP"
      },
      "source": [
        "\n",
        "    \n",
        "## **PART 1 [35 points]: Language Modeling using ngrams**\n",
        "<br />    \n",
        "\n",
        "You have been tasked with developing a language model to complete messages that for some reason arrive incomplete to a disaster response station. Given the delicate situation, you will have to be extra careful. Each word in the sentence conveys a lot of information, and improper handling of the data could cause someone to come to harm. \n",
        "\n",
        "Your language model will be based on bigrams. You'll develop your own sub-word tokenization to analyze disaster messages from multiple natural disasters. All the sentences are translated into English.\n",
        "    \n",
        "    \n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G-7bWnyHXkQ"
      },
      "source": [
        "### **PART 1: Questions**\n",
        "<br />\n",
        "\n",
        "### **1.1 [5 points] PREPROCESS THE DATASET**\n",
        "<br />\n",
        "\n",
        "**1.1.1** - Read in the dataset `disaster_response_messages_training.csv` and select only the column \"message\" and display the head of the DataFrame.\n",
        "<br /><br />\n",
        "\n",
        "**1.1.2** - Define a function `clean_data` that takes the data frame as input, converts the characters to lower case and removes any non-alphanumeric characters,  adds the start token `<s>` and the end token `</s>` to every sentence (row) in the data frame and returns the processed data frame.\n",
        "<br />\n",
        "**Sample Input:** \"Is there a dog^ on the road?\" <br />\n",
        "**Sample Output:** \"\\<s> is there a dog on the road \\</s>\"\n",
        "<br /><br />\n",
        "\n",
        "\n",
        "**1.1.3** - Split the dataset into train and test sets. The proportion should be 0.95 and 0.05, respectively. You will create the language model based on the train set and validate your results on the test set.\n",
        "<br /><br />    \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "### **1.2 [8 points] TOKENIZE AND COUNT**\n",
        "<br />\n",
        "\n",
        "In this section, you will create three different tokenizers that you will build LM based on. The tokenization functions must divide the text into tokens, count their frequency and return a dictionary with a mapping of token to number.\n",
        "<br />\n",
        "\n",
        "**1.2.1** - Create your own tokenization function ('tokenizer_1') based on whitespace. Pick the top 1000 tokens with the highest frequency to include in the vocabulary. Include the `<UNK>` token for out of the vocabulary (OOV) words.  <br /><br />\n",
        "\n",
        "**1.2.2** - Create a second tokenization function ('tokenizer_2') based on whitespace, but do not limit the vocabulary size.\n",
        "<br /><br />\n",
        "\n",
        "**1.2.3** - Create a third tokenization function ('tokenizer_3') based on sub-words. You have to define a set of common sub-words in the English language, for example, the subtokens _ing_ and _n't_. Here again, do not limit the vocabulary size.\n",
        "\n",
        "In this example, the sentence \"_It is raining outside_\" would be tokenized as [_It_, _is_, _rain_, _ing_, _outside_ ].\n",
        "\n",
        "\n",
        "**Note:** Use words only from the train data to create the vocabulary. Add an additional `<UNK>` token for **1.2.2** and **1.2.3** to handle new words found in the test set. Remove the empty character token as it provides no information\n",
        "<br /><br />\n",
        "    \n",
        "### **1.3 [6 points] CONSTRUCTING BIGRAMS**\n",
        "<br />\n",
        "\n",
        "**1.3.1** - Using each of the tokenizer functions you created, split each sentence into tokens in their numerical representation. \n",
        "<br /><br />\n",
        "\n",
        "**1.3.2** - For each tokenizer, count the occurances of each bigram (w1,w2) in the train dataset and divide them by the total occurences of the first word (w1). This will give you the probability of each bigram.\n",
        "<br /><br />\n",
        "    \n",
        "    \n",
        "### **1.4 [8 points] PREDICTING THE NEXT WORDS**\n",
        "<br />\n",
        "\n",
        "**1.4.1** - Simulate incomplete messages by dividing each sentence of the test set in two. The first $75\\%$ will represent the received message, and the final $25\\%$ will convey the missing information. You will use this dataset to evaluate the predictions of your language model.\n",
        "    \n",
        "For example in the sentence: \"*I will go out on a vacation, now that my semester ended.*\"\n",
        "\n",
        "The first 75% will be \"*I will go out on a vacation, now*\"\n",
        "\n",
        "The last 25% will be \"*that my semeter ended*\"\n",
        "\n",
        "Your aim is to predict the last part by giving your model the first \"part\" of the sentence.\n",
        "\n",
        "\n",
        "**Note:** In an n-gram language model, only the last $n-1$ words are used to make a prediction. \n",
        "\n",
        "For example, for the above sentence, if you are using bigrams, the input to your model would only be \"now\" and you are expected to predict \"that\". \n",
        "<br /><br />\n",
        "\n",
        "    \n",
        "**1.4.2** - Given 5 sentences from the previous question (test set), predict the next word. \n",
        "Append this predicted word to the input sequence and predict the next one. Repeat this process until you reach the 10th predicted token or the end of a sentence (end of a sentence - `</s>`). Compare your results qualitatively with the original sentences. Do the results make sense wrt the context and semantics?\n",
        "\n",
        "Repeat this for all the models built using different tokenization techniques.\n",
        "\n",
        "\n",
        "**Note:** For model 2 and 3 (using tokenizer 2 and 3), if there is an `<UNK>` word as the last word in the test set, predict the next word based on unigram probabilities (calculate this by using word count from Section **1.2**).\n",
        "<br /><br />\n",
        "\n",
        "**1.4.3** - Repeat the same exercise, for all 3 models, but this time, the next token will be sampled from a distribution given by the bigram frequency. Compare and comment on the results?\n",
        "\n",
        "\n",
        "**Hint:** In a model of two bigrams with frequencies 0.7 and 0.3, a deterministic prediction will only predict the first bigram. Sampling from a distribution, will enable the model to predict the second bigram with a probability of 0.3. In this way we can still predict infrequent tokens. \n",
        "<br /><br />\n",
        "    \n",
        "\n",
        "### **1.5 [5 points] EVALUATE THE LANGUAGE MODELS**\n",
        "<br />\n",
        "\n",
        "    \n",
        "**1.5.1** - For each of your models, compute the average perplexity on the test set (These are the complete test messages as tokenized in 1.3.1, **not** the incomplete test messages from 1.4.1). If the tokens of the test set are not present in the train split, define a minimum probability (smoothing). Based on this metric, which model is better?\n",
        "\n",
        "**Note:** Use the bigram probabilities for this. N (from the perplexity formula) - Number of words in the sentence.\n",
        "<br /><br />\n",
        "\n",
        "**1.5.2** - Given the perplexities, which model do you think is better? Why do you think so? Does this reflect the quality of the prediction as seen in part 1.4? \n",
        " What is the effect of UNK words?\n",
        "\n",
        "<br /><br />\n",
        "\n",
        "### **1.6 [3 points] HOMEWORK QUIZ**\n",
        "<br />\n",
        "\n",
        "After attempting this part of the homework, answer the questions on edStem. All the questions depend on this part of the homework and you will not be able to answer them without attempting this part.\n",
        "\n",
        "<br /><br />\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZQGJVcwx6q5"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf9ieRV5NU38"
      },
      "source": [
        "## **PART 1: Solutions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0Zhd1UxHXkR"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "    \n",
        "### **1.1 [5 points] PREPROCESS THE DATASET**\n",
        "<br />\n",
        "\n",
        "**1.1.1** - Read in the dataset `disaster_response_messages_training.csv`. Select only the column \"message\" and display the head of the DataFrame.\n",
        "<br />\n",
        "\n",
        "If you want to download the file you can get it from [here](https://drive.google.com/uc?id=1JRWRywWDZRdxTG1n9H9xTHXNapNdrTOJ&export=download)\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0--qw-2RHXkR"
      },
      "outputs": [],
      "source": [
        "file_path = \"https://drive.google.com/uc?id=1JRWRywWDZRdxTG1n9H9xTHXNapNdrTOJ&export=download\"\n",
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haGkdXvqHXkS"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "    \n",
        "**1.1.2** - Define a function `clean_data` that takes the data frame as input, converts the characters to lower case and removes any non-alphanumeric,  adds the start token `<s>` and the end token `</s>` to every sentence (row) in the data frame and returns the processed data frame.\n",
        "<br />\n",
        "**Sample Input:** \"Is there a dog^ on the road?\" <br />\n",
        "**Sample Output:** \"\\<s> is there a dog on the road \\</s>\"\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzSqQLiRHXkS"
      },
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE_csbO_HXkS"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "**1.1.3** - Split the dataset into train and test sets. The proportion should be 0.95 and 0.05, respectively. You will create the language model based on the train set and validate your results on the test set.\n",
        "<br /><br />  \n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqhLV4IDHXkT"
      },
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE3BueW8HXkT"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "### **1.2 [8 points] TOKENIZE AND COUNT**\n",
        "<br />\n",
        "\n",
        "In this section, you will create three different tokenizers and build an LM based on each one of them. The tokenization functions must divide the text into tokens, count their frequency and return a dictionary with a mapping of token to number.\n",
        "<br /><br />\n",
        "    \n",
        "**Note:** Use words only from the train data to create the vocabulary. Add an additional `<UNK>` token for **1.2.2** and **1.2.3** to handle new words found in the test set. Remove the empty character token as it provides no information. \n",
        "<br /><br />\n",
        "\n",
        "**1.2.1** - Create your own tokenization function ('tokenizer_1') based on whitespace. Pick the top 1000 tokens with the highest frequency to include in the vocabulary. Include the `<UNK>` token for out of the vocabulary (OOV) words. \n",
        "<br /><br />\n",
        "    \n",
        "</div> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsuySgwlHXkT"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1xu8CZ-HXkU"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "**1.2.2** - Create a second tokenization function ('tokenizer_2') based on whitespace, but do not limit the vocabulary size.\n",
        "<br /><br />\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlFMii2QHXkU"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc8kGcbKHXkU"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "**1.2.3** - Create a third tokenization function ('tokenizer_3') based on sub-words. You have to define a set of common sub-words in the English language, for example, the subtokens _ing_ and _n't_.  Here again, do not limit the vocabulary size.\n",
        "    \n",
        "In this example, the sentence \"_It is raining outside_\" would be tokenized as [_It_, _is_, _rain_, _ing_, _outside_ ].\n",
        "<br /><br />\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUddvhyfHXkU"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPRIT0WCHXkV"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "### **1.3 [7 points] CONSTRUCTING BIGRAMS**\n",
        "<br />\n",
        "\n",
        "**1.3.1** - Using each of the tokenizer functions you created, split each sentence into tokens in their numerical representation. \n",
        "<br /><br />\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIgSWDWEHXkV"
      },
      "source": [
        "**Tokenizer_1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50JWqq4THXkV"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzPLeOJHHXkV"
      },
      "source": [
        "**Tokenizer_2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CB5Z1fhHXkV"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8C1SwPxHXkV"
      },
      "source": [
        "**Tokenizer_3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UL8xpqyHXkV"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCxmJSwyHXkW"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "**1.3.2** - For each tokenizer, count the occurances of each bigram (w1,w2) in the train dataset and divide them by the total occurences of the first word (w1). This will give you the probability of each bigram.\n",
        "<br /><br />\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nNj0_i9HXkW"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8icmHoiHXkW"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "### **1.4 [9 points] PREDICTING THE NEXT WORDS**\n",
        "<br />\n",
        "\n",
        "**1.4.1** - Simulate incomplete messages by dividing each sentence of the test set in two. The first $75\\%$ will represent the received message, and the final $25\\%$ will convey the missing information. You will use this dataset to evaluate the predictions of your language model.\n",
        "    \n",
        "For example in the sentence: \"*I will go out on a vacation, now that my semester ended.*\"\n",
        "\n",
        "The first 75% will be \"*I will go out on a vacation, now*\"\n",
        "\n",
        "The last 25% will be \"*that my semeter ended*\"\n",
        "\n",
        "Your aim is to predict the last part by giving your model the first \"part\" of the sentence.\n",
        "\n",
        "\n",
        "**Note:** In an n-gram language model, only the last $n-1$ words are used to make a prediction. \n",
        "\n",
        "For example, for the above sentence, if you are using bigrams, the input to your model would only be \"now\" and you are expected to predict \"that\". \n",
        "<br /><br />\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCFq-wyOHXkW"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q668WN8JHXkW"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "\n",
        "**1.4.2** - For 5 sentences from the previous question (test set), predict the next word. \n",
        "Append this predicted word to the input sequence and predict the next one. Repeat this process until you reach the 10th predicted token or the end of a sentence (end of a sentence - `</s>`). Compare your results qualitatively with the original sentences. Do the results make sense wrt the context and semantics?\n",
        "\n",
        "Repeat this for all the models built using different tokenization techniques.\n",
        "\n",
        "\n",
        "**Note:** For model 2 and 3  (using tokenizer 2 and 3),, if there is an `<UNK>` word as the last word in the test set, predict the next word based on unigram probabilities (calculate this by using word count from Section **1.2**)\n",
        "<br /><br />\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XqmN2OAHXkW"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtpZFMe8HXkX"
      },
      "source": [
        "**Tokenizer1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orucigd_HXkX"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf7IJrptHXkX"
      },
      "source": [
        "**Tokenizer2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rl3aQERDHXkX"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV0jyNHFHXkX"
      },
      "source": [
        "**Tokenizer3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMUlZeAhHXkX"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ebMOukaHXkY"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "**1.4.3** - Repeat the same exercise, but this time, the next token will be _sampled_ from a distribution given by the bigram frequency. Are the results better?\n",
        "\n",
        "In a model of two bigrams with frequencies 0.7 and 0.3, a deterministic prediction will only predict the first bigram. Sampling from a distribution, will enable the model to predict the second bigram with a probability of 0.3. In this way we can still predict infrequent tokens. \n",
        "<br /><br />\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nw5C2t38HXkY"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACZ7LVm0HXkY"
      },
      "source": [
        "**Tokenizer_1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9pISmymHXkY"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w_gG_4AHXkY"
      },
      "source": [
        "**Tokenizer_2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqYkoDt4HXkY"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB4ESZF9HXkY"
      },
      "source": [
        "**Tokenizer_3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88g1jRSMHXkZ"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZcTt2wsHXkZ"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "### **1.5 [6 points] EVALUATE THE LANGUAGE MODELS**\n",
        "<br />\n",
        "\n",
        "    \n",
        "**1.5.1** - For each of your models, compute the average perplexity on the test set (These are the complete test messages as tokenized in 1.3.1, **not** the incomplete test messages from 1.4.1). If the tokens of the test set are not present in the train split, define a minimum probability (smoothing). Based on this metric, which model is better?\n",
        "\n",
        "**Note:** Use the bigram probabilities for this. N - (from the perplexity formula) Number of words in the sentence.\n",
        "<br /><br />\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yt8RfxTJHXkZ"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyHHj10DHXkZ"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "**1.5.2** - Given the perplexities, which model do you think is better? Why do you think so? Does this reflect the quality of the prediction as seen in part 1.4? \n",
        " What is the effect of UNK words?\n",
        "<br /><br />\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSMZ8TueHXkZ"
      },
      "source": [
        "Type your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLx_dIVbwW_y"
      },
      "source": [
        "___\n",
        "___\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s8tzWckHXkf"
      },
      "source": [
        "## **PART 2 [35 points] : Language Modelling using RNNs**\n",
        "<br />    \n",
        "\n",
        "In this part of the homework, you are to build and train a new language model. For this, we will be using Prof. Protopapas's famous texts which end with `...` for prediction. Here, you will preprocess a data corpus and train your simple RNN network with it. With this network you will try to predict what he meant when he typed `...`. For this task we will use a form of transfer learning: first training a network on the larger dataset, such as IMDB reviews, and then 'fine tuning' the network to the professor's texts.\n",
        "<br /><br />\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWrWbR1eHXkf"
      },
      "source": [
        "## **PART 2: Questions**\n",
        "<br />\n",
        "\n",
        "### **2.1 [2 points] PREPROCESS THE DATASET**\n",
        "<br />\n",
        "\n",
        "**2.1.1** - Read in the dataset `imdb.csv`. Create a new dataframe by splitting each review into individual sentences. The sentences can be delimited by different characters such as period and question mark (eroteme). Call this column as `text` in the new dataframe.\n",
        "<br /><br />\n",
        "\n",
        "**2.1.2** - Define a function `clean_data` that takes the new dataframe as input and removes all html tags and non-alphanumeric characters from the dataframe. Additionally, convert all characters to lower case. Remove all the sentences where the number of words is less than 10 and higher than 30. Finally, add the start token `<s>` and the end token `</s>` to every sentence (row) in the dataframe. Return the processed the dataframe. \n",
        "<br /><br />\n",
        "\n",
        "### **2.2 [2 points] TOKENIZE THE DATASET**\n",
        "<br />\n",
        "\n",
        "**2.2.1** - Instantiate a Tokenizer for the dataset using `tensorflow.keras.preprocessing.text.Tokenizer` with a vocabulary size of 5000.  Do **not** use an additional token for unknown, out of vocabulary words (oov). That is, you will **not** have the equivalent of the `<UNK>` token.\n",
        "\n",
        "*Hint:* Remove all filters from the function as we have already perfomed data cleaning. Set the value of filter to be `''`.\n",
        "<br /><br />\n",
        "\n",
        "**2.2.2** - Fit the tokenizer on the dataset and get the sequence representation of each sentence.\n",
        "<br /><br />\n",
        "\n",
        "### **2.3 [10 points] MODELLING THE DATA**\n",
        "<br />\n",
        "\n",
        "**2.3.1** - The first step is to split the dataset into the predictors ($X$) and the response ($Y$). The predictors for each observation (sentence) are all tokens in that sentence _except_ the **last** token. The response for a given sentence is all tokens in that sentence _except_ the **first**. Using `tf.keras.preprocessing.sequence.pad_sequences` post-pad each sequence in $X$ and $Y$ to a length of 30.\n",
        "    \n",
        "**Hint:** You may need to use `tf.convert_to_tensor` on the objects returned by the padding operation. \n",
        "```\n",
        "Example:\n",
        "if token for <s> = 1 and </s> = 2\n",
        "sentence_i = [1, 48, 2498, 22, 16, 4, 4, 1554, 149, 14, 22, 2]\n",
        "x_i = [1,  48,   2498, 22, 16, 4, 4,    1554, 149, 14, 22, 0, ..., 0]\n",
        "y_i = [48, 2498, 22,   16, 4,  4, 1554, 149,  14,  22, 2,  0, ..., 0]\n",
        "```\n",
        "<br /><br />\n",
        "\n",
        "**2.3.2** - Define a simple RNN model that has an embedding layer with an embedding dimension of 300. You can define any number of RNN layers. The output of the RNN model will be a dense layer with size of the vocabulary and softmax activation. Using the functional API here may make it easier to reuse parts of the network later on.\n",
        "<br /><br />\n",
        "\n",
        "**2.3.3** - Train the model with the $X$ and $Y$ data formed in 2.3.1. Use a validation split of 0.2. The choice of number epochs and batch size is left to you.\n",
        "<br /><br />\n",
        "\n",
        "**2.3.4** - Plot the train and validation loss from the training history.\n",
        "<br /><br />\n",
        "\n",
        "### **2.4 [9 points] PREDICTING THE NEXT WORD**\n",
        "<br />\n",
        "\n",
        "**2.4.1** -Read the dataset `pp_text.csv`. Add only the  start token to each line, remove the last word and tokenize it using the tokenizer fit previously. Convert each sentence to a sequence vector and post-pad to a length of 30. This will be the input for the prediction phase.\n",
        "<br /><br />\n",
        "\n",
        "**2.4.2** - For predicting the next word, use the trained RNN model from above. \n",
        "\n",
        "NOTE - Based on your implementation, the output of the RNN model might have to be different from that of your trained network. You can make use of Keras function API for this.\n",
        "<br /><br />\n",
        "\n",
        "**2.4.3** - Choose any sentence from the list of Pavlos' texts to predict the next word. Input this to the RNN model built for prediction and print the predicted word. Try this out with multiple sentences.\n",
        "<br /><br />\n",
        "\n",
        "**2.4.4** - Do you notice any pattern in the predicted words? Do they seem approriate to the context of the texts as you understand it? What do you attribute this discrepency to? How can you resolve it?\n",
        "\n",
        "Answer in less than 150 words.\n",
        "<br /><br />\n",
        "\n",
        "### **2.5 [6 points] TRAINING AND PREDICTING WITH A DIFFERENT DATASET**\n",
        "<br />\n",
        "\n",
        "**2.5.1** - Read the dataset `cleaned_sarcasm.csv`. This dataset has been preprocessed for you, all you need to do is tokenize, convert to sequence and pad it, similar to 2.2.1, 2.2.2 and 2.3.1.\n",
        "<br /><br />\n",
        "\n",
        "**2.5.2** - Train your RNN model with this data and plot the train and validation trace plot. This part is similar to 2.3.2, 2.3.3 and 2.3.4.\n",
        "<br /><br />\n",
        "\n",
        "**2.5.3** - Repeat 2.4.1, 2.4.2 and 2.4.3 with the RNN model trained using the new dataset.\n",
        "<br /><br />\n",
        "\n",
        "**2.5.4** - How do the results with the new dataset compare to the previous ones? Why do you think so? \n",
        "\n",
        "Answer in less than 100 words.\n",
        "<br /><br />\n",
        "    \n",
        "### **2.6 [3 points] COMPLETING THE SENTENCE**\n",
        "<br />\n",
        "\n",
        "**2.6.1** Until now we have predicted a single word for a given sentence. However, what if he meant more than one word when he typed in `...`\n",
        "\n",
        "We will now predict multiple words for each input sentence. To do this we will first predict one word, append this word to the input text and then predict one more with the updated input. Continue doing this for 5 words or until the end token `</s>` (whichever comes first). \n",
        "<br /><br />\n",
        "\n",
        "### **2.7 [3 points] HOMEWORK QUIZ**\n",
        "<br />\n",
        "After attempting this part of the homework, answer the questions on edStem. All the questions depend on this part of the homework and you will not be able to answer them without attempting this part.\n",
        "\n",
        "<br />\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaQ8lfVowoy3"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "898ka8eIyMSY"
      },
      "source": [
        "## **PART 2: Solutions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfUtlwvKHXkg"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "    \n",
        "### **2.1 [2 points] PREPROCESS THE DATASET**\n",
        "<br />    \n",
        "\n",
        "**2.1.1** - Read in the dataset `imdb.csv`. Create a new dataframe by splitting each review into individual sentences. The sentences can be delimited by different characters such as period and question mark (eroteme). Call this column as `text` in the new dataframe.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "B1HuszSR0_C7",
        "outputId": "ecf7f09b-eb3a-478c-f1a3-44fe1ec3a16f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  polarity\n",
              "0  first think another Disney movie, might good, ...         1\n",
              "1  Put aside Dr. House repeat missed, Desperate H...         0\n",
              "2  big fan Stephen King's work, film made even gr...         1\n",
              "3  watched horrid thing TV. Needless say one movi...         0\n",
              "4  truly enjoyed film. acting terrific plot. Jeff...         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a20d69df-e9d5-4c57-af6e-7294f3081537\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>first think another Disney movie, might good, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Put aside Dr. House repeat missed, Desperate H...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>big fan Stephen King's work, film made even gr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>watched horrid thing TV. Needless say one movi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>truly enjoyed film. acting terrific plot. Jeff...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a20d69df-e9d5-4c57-af6e-7294f3081537')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a20d69df-e9d5-4c57-af6e-7294f3081537 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a20d69df-e9d5-4c57-af6e-7294f3081537');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Read the data\n",
        "file_path = \"https://drive.google.com/uc?id=1QDSIaV4iERVgc3b0xkW0u7EuTyQ8vncm&export=download\"\n",
        "data = pd.read_csv(file_path, encoding='latin1')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The shape of the data is {data.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZGeJpXoXa8V",
        "outputId": "9cb9ae1d-8adb-404a-91eb-560280be3d4a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the data is (10000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1eLvtBYfHXkg"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "from nltk import tokenize \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "YmoK7BOB7EtN"
      },
      "outputs": [],
      "source": [
        "df_series = data['text'].apply(lambda x : sent_tokenize(x)) # this converts each reviews into list of sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFtvxAtb7mbB",
        "outputId": "270cf633-922e-46c1-9789-a5ae1bd44729"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [first think another Disney movie, might good,...\n",
              "1    [Put aside Dr. House repeat missed, Desperate ...\n",
              "2    [big fan Stephen King's work, film made even g...\n",
              "3    [watched horrid thing TV., Needless say one mo...\n",
              "4    [truly enjoyed film., acting terrific plot., J...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "df_series.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "unaxKUiP8waM"
      },
      "outputs": [],
      "source": [
        "# sentence_list will store each of the sentences\n",
        "sentence_list = []\n",
        "for review_list in df_series:\n",
        "    for sentence in review_list:\n",
        "        sentence_list.append(sentence)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GKlMdn8r9ggy",
        "outputId": "91a58cae-1e24-4662-f37e-0fa82deb4f0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text\n",
              "0  first think another Disney movie, might good, ...\n",
              "1                     watch it, can't help enjoy it.\n",
              "2                                   ages love movie.\n",
              "3    first saw movie 10 8 years later still love it!\n",
              "4        Danny Glover superb could play part better."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5072e27-273b-4a08-979b-3c2369f92f5d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>first think another Disney movie, might good, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>watch it, can't help enjoy it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ages love movie.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>first saw movie 10 8 years later still love it!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Danny Glover superb could play part better.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5072e27-273b-4a08-979b-3c2369f92f5d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5072e27-273b-4a08-979b-3c2369f92f5d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5072e27-273b-4a08-979b-3c2369f92f5d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "df = pd.DataFrame(data=sentence_list, columns=['text'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvCroMOhHXkg"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "**2.1.2** - Define a function `clean_data` that takes the new dataframe as input and removes all html tags and non-alphabetic characters from the dataframe. Additionally, convert all characters to lower case. Remove all the sentences where the number of words is less than 10 and higher than 30. Finally, add the start token `<s>` and the end token `</s>` to every sentence (row) in the dataframe. Return the processed the dataframe. \n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "8Q14FLh9HXkg"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "\n",
        "def clean_data(df):\n",
        "    df['text'] = df['text'].apply(lambda x : x.lower())\n",
        "    \n",
        "    # Remove HTML\n",
        "    df['text'] = df['text'].apply(lambda x: re.sub('<br /><br />', ' ', x))\n",
        "    \n",
        "    # Replace all none alphanumeric characters with spaces\n",
        "    df['text'] = df['text'].apply(lambda x : re.sub(r'[^a-zA-Z0\\s]', '', x))\n",
        "\n",
        "    # getting rows based on number of words present\n",
        "    df['count_of_words'] = df['text'].apply(lambda x : len(x.split()))\n",
        "    df                   = df[(df['count_of_words'] >= 10) & (df['count_of_words'] <= 30)]\n",
        "\n",
        "    # adding start and end token\n",
        "    df['text']           = df['text'].apply(lambda x: '<s> '+x+' </s>')\n",
        "    \n",
        "    del df['count_of_words']\n",
        "\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "xyIKxejwG-Q3",
        "outputId": "8fd3b8de-b43d-4626-8c7a-e3e1de585011"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 text\n",
              "0   <s> first think another disney movie might goo...\n",
              "9   <s> put aside dr house repeat missed desperate...\n",
              "11  <s> never thought id say this want  minutes fa...\n",
              "12  <s> recognized stable actors the usual suspect...\n",
              "14  <s> dullsville my favorite parts office girl m..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06308ed8-1279-41b0-9041-22d944d82a30\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt; first think another disney movie might goo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>&lt;s&gt; put aside dr house repeat missed desperate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>&lt;s&gt; never thought id say this want  minutes fa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>&lt;s&gt; recognized stable actors the usual suspect...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>&lt;s&gt; dullsville my favorite parts office girl m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06308ed8-1279-41b0-9041-22d944d82a30')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-06308ed8-1279-41b0-9041-22d944d82a30 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-06308ed8-1279-41b0-9041-22d944d82a30');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "df = clean_data(df)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the most frequent words\n",
        "dic= {}\n",
        "for i in range(df.shape[0]):\n",
        "\n",
        "  for word in df.iloc[i]['text'].split():\n",
        "    try:\n",
        "      dic[word] = dic[word]+1\n",
        "\n",
        "    except:\n",
        "       dic[word] =1 \n",
        "\n"
      ],
      "metadata": {
        "id": "aI6wHmcX5wIh"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# answer for the quiz question\n",
        "print(f'frequency of the: {dic[\"the\"]}')\n",
        "print(f'frequency of chime: {dic[\"chime\"]}')\n",
        "print(f'frequency of film: {dic[\"film\"]}')\n",
        "print(f'frequency of swim: {dic[\"swim\"]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rhe2t8ZR698B",
        "outputId": "c6c2e0b1-c426-4b8b-9b01-f27b0dbd0a61"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frequency of the: 3199\n",
            "frequency of chime: 1\n",
            "frequency of film: 9334\n",
            "frequency of swim: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRMMXqdMHXkh"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "    \n",
        "### **2.2 [2 points] TOKENIZE THE DATASET**\n",
        "    \n",
        "<br />\n",
        "\n",
        "**2.2.1** - Instantiate a Tokenizer for the dataset using `tensorflow.keras.preprocessing.text.Tokenizer` with a vocabulary size of 5000.Do **not** use an additional token for unknown, out of vocabulary words (oov). That is, you will **not** have the equivalent of the `<UNK>` token.\n",
        "\n",
        "*Hint:* Remove all filters from the function as we have already perfomed data cleaning. Set the value of filter to be `''`.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "zxRYzZAlHXkh"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "vocab_size = 5000 \n",
        "tokenizer_tf = tf.keras.preprocessing.text.Tokenizer(\n",
        "    num_words=vocab_size,\n",
        "    filters='',\n",
        "    lower=True,\n",
        "    split=' ',\n",
        "    char_level=False,\n",
        "    oov_token=None,\n",
        ")\n",
        "\n",
        "# QUESTION TO ASK : when we apply tokenizer with no filters, does it mean it gives a seperate token for the expressions. Also where do we provide \n",
        "# token for unknown words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FoDsoziHXkh"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "**2.2.2** - Fit the tokenizer on the dataset and get the sequence representation of each sentence.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NfcKfHC8HXkh",
        "outputId": "6ef1deb1-3a14-4f53-bdec-4d3bb3319343"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 text  \\\n",
              "0   <s> first think another disney movie might goo...   \n",
              "9   <s> put aside dr house repeat missed desperate...   \n",
              "11  <s> never thought id say this want  minutes fa...   \n",
              "12  <s> recognized stable actors the usual suspect...   \n",
              "14  <s> dullsville my favorite parts office girl m...   \n",
              "\n",
              "                                    sentence_as_token  \n",
              "0       [1, 22, 32, 68, 825, 4, 122, 8, 7, 279, 4, 2]  \n",
              "9   [1, 178, 999, 836, 208, 3126, 1006, 1630, 63, ...  \n",
              "11  [1, 40, 118, 361, 61, 53, 96, 142, 1863, 59, 1...  \n",
              "12  [1, 3870, 73, 9, 574, 2323, 118, 737, 1405, 18...  \n",
              "14  [1, 833, 497, 416, 945, 153, 65, 41, 1242, 396...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34d8ee08-c1d9-44e5-aada-019d63aa373f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentence_as_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt; first think another disney movie might goo...</td>\n",
              "      <td>[1, 22, 32, 68, 825, 4, 122, 8, 7, 279, 4, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>&lt;s&gt; put aside dr house repeat missed desperate...</td>\n",
              "      <td>[1, 178, 999, 836, 208, 3126, 1006, 1630, 63, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>&lt;s&gt; never thought id say this want  minutes fa...</td>\n",
              "      <td>[1, 40, 118, 361, 61, 53, 96, 142, 1863, 59, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>&lt;s&gt; recognized stable actors the usual suspect...</td>\n",
              "      <td>[1, 3870, 73, 9, 574, 2323, 118, 737, 1405, 18...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>&lt;s&gt; dullsville my favorite parts office girl m...</td>\n",
              "      <td>[1, 833, 497, 416, 945, 153, 65, 41, 1242, 396...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34d8ee08-c1d9-44e5-aada-019d63aa373f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34d8ee08-c1d9-44e5-aada-019d63aa373f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34d8ee08-c1d9-44e5-aada-019d63aa373f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# Your code here\n",
        "tokenizer_tf.fit_on_texts(df['text'])\n",
        "\n",
        "df['sentence_as_token'] = tokenizer_tf.texts_to_sequences(df['text'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9VpgS8xpH8M"
      },
      "outputs": [],
      "source": [
        "# vocab_size = len(tokenizer_tf.word_index) + 1 # tokenizer_tf.word_index is a dictionary maping words to token, +1 is for reverse padding, index0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnaKCmlZHXkh"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "    \n",
        "### **2.3 [10 points] MODELLING THE DATA**\n",
        "    \n",
        "**2.3.1** - The first step is to split the dataset into the predictors ($X$) and the response ($Y$). The predictors for each observation (sentence) are all tokens in that sentence _except_ the **last** token. The response for a given sentence is all tokens in that sentence _except_ the **first**. Using `tf.keras.preprocessing.sequence.pad_sequences` post-pad each sequence in $X$ and $Y$ to a length of 30.\n",
        "    \n",
        "```\n",
        "Example:\n",
        "if token for <s> = 1 and </s> = 2\n",
        "sentence_i = [1, 48, 2498, 22, 16, 4, 4, 1554, 149, 14, 22, 2]\n",
        "x_i = [1,  48,   2498, 22, 16, 4, 4,    1554, 149, 14, 22, 0, ..., 0]\n",
        "y_i = [48, 2498, 22,   16, 4,  4, 1554, 149,  14,  22, 2,  0, ..., 0]\n",
        "```\n",
        "**Hint:** You may need to use `tf.convert_to_tensor` on the objects returned by the padding operation. \n",
        "</div>    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQYWGPhNHXkh",
        "outputId": "937fe33b-d4e9-4e43-ef53-11dd9f79956d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49054, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# Your code here\n",
        "all_data = tf.keras.preprocessing.sequence.pad_sequences(df['sentence_as_token'],padding = 'post')\n",
        "all_data.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pQzG8YRQ8Tk",
        "outputId": "6d62e288-3bcd-470e-948e-f26172500560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X :(49054, 30), shape of y: (49054, 30)\n"
          ]
        }
      ],
      "source": [
        "X = all_data[:,0:30]\n",
        "y = all_data[:,1:31]\n",
        "print(f'Shape of X :{X.shape}, shape of y: {y.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X and Y label of one sample\n",
        "print(f'X label: {X[0]}')\n",
        "print(f'Y label: {y[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPRfh2hfX5SM",
        "outputId": "01555ef7-16a1-43ce-dd88-d6ad516f84d6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X label: [  1  22  32  68 825   4 122   8   7 279   4   2   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "Y label: [ 22  32  68 825   4 122   8   7 279   4   2   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.convert_to_tensor(X) #converting to tensor\n",
        "y = tf.convert_to_tensor(y)"
      ],
      "metadata": {
        "id": "Ajrg5seKT1of"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMJhDMlylwQk",
        "outputId": "d8ac503c-455a-4626-fdae-fa3a5d81113b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (49054, 30)\n",
            "Y shape: (49054, 30)\n"
          ]
        }
      ],
      "source": [
        "print(f'X shape: {X.shape}')\n",
        "print(f'Y shape: {y.shape }')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-GPuG5XHXkh"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "    \n",
        "**2.3.2** - Define a simple RNN model that has an embedding layer with an embedding dimension of 300. You can define any number of RNN layers. The output of the RNN model will be a dense layer with size of the vocabulary and softmax activation. Using the functional API here may make it easier to reuse parts of the network later on.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'vocab size is : {vocab_size}') # we defined it earlier during tokenizeation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grCmCkziwkN-",
        "outputId": "faeb75ea-008f-42ad-8586-a9b350bfa6a1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size is : 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aesKHFlJQbAf"
      },
      "outputs": [],
      "source": [
        "# vocab_size = len(tokenizer_tf.word_index)+1\n",
        "# vocab_size"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1D convolutions and recurrent layers use (batch_size, sequence_length, features)"
      ],
      "metadata": {
        "id": "cyYGBwyMzdIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "inputs = Input(shape=(30,))\n",
        "\n",
        "embedding = Embedding(input_dim= vocab_size+1, output_dim = 300,mask_zero=True)(inputs) # set mask_zero = True see the difference\n",
        "\n",
        "simple_rnn = SimpleRNN(50,input_shape= (300,),return_sequences= True,name ='rnn_layer')(embedding) # return_sequences = True, since we have a sequence and we need to do backprop and calculate loss for each element in the sequence\n",
        "final_layer = Dense(vocab_size+1,activation= 'softmax',name ='final_dense_layer'  )(simple_rnn)\n",
        "\n",
        "rnn_model = Model(inputs=inputs,outputs=final_layer)\n",
        "rnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUG8TAxdZxEc",
        "outputId": "01acd3f1-ef5c-4c9f-b7ef-a6c3cabb7001"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 30)]              0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 30, 300)           1500300   \n",
            "                                                                 \n",
            " rnn_layer (SimpleRNN)       (None, 30, 50)            17550     \n",
            "                                                                 \n",
            " final_dense_layer (Dense)   (None, 30, 5001)          255051    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,772,901\n",
            "Trainable params: 1,772,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAwjekNXq2kz"
      },
      "source": [
        "*doubt- what would happen if we made return_sequences and return_state = True*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyhMgVppzEUC"
      },
      "outputs": [],
      "source": [
        "# rnn_model = Sequential()\n",
        "# rnn_model.add(Input(shape=(1))) #or 30\n",
        "# rnn_model.add(Embedding(input_dim = vocab_size, output_dim=300 ,mask_zero=True)) # we can pass input length(not input_dim) as 30 too, but none as well, which is default\n",
        "# rnn_model.add(tf.keras.layers.SimpleRNN(units=50,return_sequences=True,activation='tanh'))\n",
        "# # rnn_model.add(tf.keras.layers.SimpleRNN(units=50,return_sequences=True,activation='tanh'))\n",
        "# rnn_model.add(Dense(vocab_size,activation='softmax'))\n",
        "# rnn_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnWND6RSHXki"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "**2.3.3** - Train the model with the $X$ and $Y$ data formed in 2.3.1. Use a validation split of 0.2. The choice of number epochs and batch size is left to you.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "GGt185PRHXki"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "rnn_model.compile(loss= tf.keras.losses.SparseCategoricalCrossentropy(),optimizer= tf.keras.optimizers.Adam(),\n",
        "            metrics = [tf.keras.metrics.SparseCategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_of_epochs =20\n",
        "history_rnn = rnn_model.fit(X,y, batch_size = 256, epochs =no_of_epochs, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLAKn2WHHFsg",
        "outputId": "95e95c53-bdf0-4907-d81f-06be33109666"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "154/154 [==============================] - 17s 69ms/step - loss: 3.6269 - sparse_categorical_accuracy: 0.0629 - val_loss: 3.4816 - val_sparse_categorical_accuracy: 0.1238\n",
            "Epoch 2/20\n",
            "154/154 [==============================] - 10s 65ms/step - loss: 3.3993 - sparse_categorical_accuracy: 0.1290 - val_loss: 3.3738 - val_sparse_categorical_accuracy: 0.1345\n",
            "Epoch 3/20\n",
            "154/154 [==============================] - 11s 71ms/step - loss: 3.3234 - sparse_categorical_accuracy: 0.1360 - val_loss: 3.3246 - val_sparse_categorical_accuracy: 0.1372\n",
            "Epoch 4/20\n",
            "154/154 [==============================] - 10s 66ms/step - loss: 3.2821 - sparse_categorical_accuracy: 0.1403 - val_loss: 3.2995 - val_sparse_categorical_accuracy: 0.1406\n",
            "Epoch 5/20\n",
            "154/154 [==============================] - 10s 67ms/step - loss: 3.2533 - sparse_categorical_accuracy: 0.1440 - val_loss: 3.2774 - val_sparse_categorical_accuracy: 0.1439\n",
            "Epoch 6/20\n",
            "154/154 [==============================] - 11s 71ms/step - loss: 3.2257 - sparse_categorical_accuracy: 0.1462 - val_loss: 3.2576 - val_sparse_categorical_accuracy: 0.1451\n",
            "Epoch 7/20\n",
            "154/154 [==============================] - 11s 73ms/step - loss: 3.2002 - sparse_categorical_accuracy: 0.1478 - val_loss: 3.2408 - val_sparse_categorical_accuracy: 0.1462\n",
            "Epoch 8/20\n",
            "154/154 [==============================] - 10s 68ms/step - loss: 3.1774 - sparse_categorical_accuracy: 0.1496 - val_loss: 3.2272 - val_sparse_categorical_accuracy: 0.1478\n",
            "Epoch 9/20\n",
            "154/154 [==============================] - 10s 67ms/step - loss: 3.1552 - sparse_categorical_accuracy: 0.1518 - val_loss: 3.2149 - val_sparse_categorical_accuracy: 0.1490\n",
            "Epoch 10/20\n",
            "154/154 [==============================] - 10s 67ms/step - loss: 3.1343 - sparse_categorical_accuracy: 0.1534 - val_loss: 3.2038 - val_sparse_categorical_accuracy: 0.1498\n",
            "Epoch 11/20\n",
            "154/154 [==============================] - 10s 67ms/step - loss: 3.1148 - sparse_categorical_accuracy: 0.1551 - val_loss: 3.1948 - val_sparse_categorical_accuracy: 0.1504\n",
            "Epoch 12/20\n",
            "154/154 [==============================] - 10s 68ms/step - loss: 3.0970 - sparse_categorical_accuracy: 0.1565 - val_loss: 3.1884 - val_sparse_categorical_accuracy: 0.1516\n",
            "Epoch 13/20\n",
            "154/154 [==============================] - 10s 66ms/step - loss: 3.0808 - sparse_categorical_accuracy: 0.1582 - val_loss: 3.1837 - val_sparse_categorical_accuracy: 0.1518\n",
            "Epoch 14/20\n",
            "154/154 [==============================] - 10s 68ms/step - loss: 3.0660 - sparse_categorical_accuracy: 0.1596 - val_loss: 3.1792 - val_sparse_categorical_accuracy: 0.1522\n",
            "Epoch 15/20\n",
            "154/154 [==============================] - 10s 67ms/step - loss: 3.0523 - sparse_categorical_accuracy: 0.1609 - val_loss: 3.1777 - val_sparse_categorical_accuracy: 0.1518\n",
            "Epoch 16/20\n",
            "154/154 [==============================] - 10s 67ms/step - loss: 3.0393 - sparse_categorical_accuracy: 0.1620 - val_loss: 3.1752 - val_sparse_categorical_accuracy: 0.1527\n",
            "Epoch 17/20\n",
            "154/154 [==============================] - 10s 68ms/step - loss: 3.0273 - sparse_categorical_accuracy: 0.1631 - val_loss: 3.1736 - val_sparse_categorical_accuracy: 0.1538\n",
            "Epoch 18/20\n",
            "154/154 [==============================] - 11s 70ms/step - loss: 3.0164 - sparse_categorical_accuracy: 0.1639 - val_loss: 3.1737 - val_sparse_categorical_accuracy: 0.1532\n",
            "Epoch 19/20\n",
            "154/154 [==============================] - 10s 67ms/step - loss: 3.0055 - sparse_categorical_accuracy: 0.1648 - val_loss: 3.1732 - val_sparse_categorical_accuracy: 0.1537\n",
            "Epoch 20/20\n",
            "154/154 [==============================] - 10s 66ms/step - loss: 2.9954 - sparse_categorical_accuracy: 0.1656 - val_loss: 3.1737 - val_sparse_categorical_accuracy: 0.1539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eTadAXqHXki"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "**2.3.4** - Plot the train and validation loss from the training history.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "UPtOE1vd9sIG"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Pf0Jp5WS0NLI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "dd8af94c-566d-4fc4-9805-c631050bd51a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 936x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(13,10))\n",
        "\n",
        "plt.plot(list(range(1,no_of_epochs+1)), history_rnn.history['loss'], label='Train loss')\n",
        "plt.plot(list(range(1,no_of_epochs+1)), history_rnn.history['val_loss'], label='Val loss')\n",
        "plt.legend()\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHZAUp9vHXki"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "### **2.4 [10 points] PREDICTING THE NEXT WORD**\n",
        "    \n",
        "<br />\n",
        "    \n",
        "**2.4.1** - Read the dataset `pp_text.csv`. Add only the  start token to each line, remove the last word and tokenize it using the tokenizer fit previously. Convert each sentence to a sequence vector and post-pad to a length of 30. This will be the input for the prediction phase.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "kJTWuX7VHXki",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f525f3c6-61b4-458d-f7c6-1df48d88c675"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text\n",
              "0  When you make changes please always check if e...\n",
              "1                          I found them very similar\n",
              "2  Give some overview of what the exercises are a...\n",
              "3                         Honestly I do not remember\n",
              "4                            Can you check the video"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d03776d-5af1-4dcd-9f81-0a1cb37fd14a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>When you make changes please always check if e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I found them very similar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Give some overview of what the exercises are a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Honestly I do not remember</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Can you check the video</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d03776d-5af1-4dcd-9f81-0a1cb37fd14a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d03776d-5af1-4dcd-9f81-0a1cb37fd14a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d03776d-5af1-4dcd-9f81-0a1cb37fd14a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# Read the data\n",
        "file_path = \"https://drive.google.com/uc?id=1sFolPhc31mqvCxC3JxORmur21e28XeA-&export=download\"\n",
        "df_pred = pd.read_csv(file_path)\n",
        "df_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Shape of df_pred : {df_pred.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkRapScx4xxW",
        "outputId": "e001259d-4e47-4a12-dbff-44333c3616eb"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of df_pred : (35, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Should we do preprocessing using the clean function defined above?"
      ],
      "metadata": {
        "id": "dJtCzrtjD1A5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred['last_word'] = df_pred['Text'].apply(lambda x: x.rsplit(' ',1)[1])\n",
        "df_pred['Text'] = df_pred['Text'].apply(lambda x: x.rsplit(' ',1)[0]) # removing the last word using reverse split\n",
        "df_pred['Text'] = df_pred['Text'].apply(lambda x: '<s> ' + x ) # adding initial token to sentence\n",
        "df_pred.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FhvB7rKkCMaL",
        "outputId": "7d6913cc-c400-4223-babf-892850b57d57"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text last_word\n",
              "0  <s> When you make changes please always check ...   working\n",
              "1                              <s> I found them very   similar\n",
              "2  <s> Give some overview of what the exercises a...     there\n",
              "3                              <s> Honestly I do not  remember\n",
              "4                              <s> Can you check the     video"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20be3d45-9a99-4b31-a0ee-8f2dababefcb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>last_word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt; When you make changes please always check ...</td>\n",
              "      <td>working</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;s&gt; I found them very</td>\n",
              "      <td>similar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;s&gt; Give some overview of what the exercises a...</td>\n",
              "      <td>there</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;s&gt; Honestly I do not</td>\n",
              "      <td>remember</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;s&gt; Can you check the</td>\n",
              "      <td>video</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20be3d45-9a99-4b31-a0ee-8f2dababefcb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20be3d45-9a99-4b31-a0ee-8f2dababefcb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20be3d45-9a99-4b31-a0ee-8f2dababefcb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adding the last word(y variable) as a column so that we can compare with the predicted word\n",
        "\n",
        "df_pred['text_as_seq'] = tokenizer_tf.texts_to_sequences(df_pred['Text'])\n",
        "df_pred['y_last_word'] = tokenizer_tf.texts_to_sequences(df_pred['last_word'])\n",
        "df_pred.head() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sLjQvpdRA9w1",
        "outputId": "dfac0911-e86a-4c9e-f52e-8d38c902ae92"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text last_word  \\\n",
              "0  <s> When you make changes please always check ...   working   \n",
              "1                              <s> I found them very   similar   \n",
              "2  <s> Give some overview of what the exercises a...     there   \n",
              "3                              <s> Honestly I do not  remember   \n",
              "4                              <s> Can you check the     video   \n",
              "\n",
              "                                         text_as_seq y_last_word  \n",
              "0  [1, 1064, 261, 24, 1319, 695, 109, 1004, 324, ...       [708]  \n",
              "1                            [1, 49, 168, 193, 1580]       [676]  \n",
              "2  [1, 115, 1250, 533, 532, 9, 828, 86, 858, 1431...       [189]  \n",
              "3                            [1, 1295, 49, 517, 316]       [314]  \n",
              "4                            [1, 2155, 261, 1004, 9]       [321]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6653ac45-aeb2-46bf-ac2e-fcccfdc3ac87\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>last_word</th>\n",
              "      <th>text_as_seq</th>\n",
              "      <th>y_last_word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt; When you make changes please always check ...</td>\n",
              "      <td>working</td>\n",
              "      <td>[1, 1064, 261, 24, 1319, 695, 109, 1004, 324, ...</td>\n",
              "      <td>[708]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;s&gt; I found them very</td>\n",
              "      <td>similar</td>\n",
              "      <td>[1, 49, 168, 193, 1580]</td>\n",
              "      <td>[676]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;s&gt; Give some overview of what the exercises a...</td>\n",
              "      <td>there</td>\n",
              "      <td>[1, 115, 1250, 533, 532, 9, 828, 86, 858, 1431...</td>\n",
              "      <td>[189]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;s&gt; Honestly I do not</td>\n",
              "      <td>remember</td>\n",
              "      <td>[1, 1295, 49, 517, 316]</td>\n",
              "      <td>[314]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;s&gt; Can you check the</td>\n",
              "      <td>video</td>\n",
              "      <td>[1, 2155, 261, 1004, 9]</td>\n",
              "      <td>[321]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6653ac45-aeb2-46bf-ac2e-fcccfdc3ac87')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6653ac45-aeb2-46bf-ac2e-fcccfdc3ac87 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6653ac45-aeb2-46bf-ac2e-fcccfdc3ac87');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# padding the prediction data\n",
        "maxlen=30\n",
        "X_pred_padded = tf.keras.preprocessing.sequence.pad_sequences(df_pred['text_as_seq'], maxlen =30, padding='post')\n",
        "\n",
        "X_pred_padded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLzNL3EEKG4i",
        "outputId": "6d1e6066-1cd1-4d97-e313-688ea126fa80"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nVrOByOHXki"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "\n",
        "**2.4.2** - Define a simple RNN model with the trained weights of the trained RNN model for predicting the next word. You can make use of Keras function API to reuse the previously written code. The output of this new model is the last element of the RNN output defined earlier.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model.summary() # archtitecture of previous rnn model "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siIllLvBJc8y",
        "outputId": "0fe68074-c6f9-4ed7-cf59-3fffa773cd34"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 30)]              0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 30, 300)           1500300   \n",
            "                                                                 \n",
            " rnn_layer (SimpleRNN)       (None, 30, 50)            17550     \n",
            "                                                                 \n",
            " final_dense_layer (Dense)   (None, 30, 5001)          255051    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,772,901\n",
            "Trainable params: 1,772,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating a new rnn model with similar architecture but with return sequence = False, that would give us the hiddenstate of only the last element, needed to predict the next word**"
      ],
      "metadata": {
        "id": "UDYqgHxXDsMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_inputs = Input(shape=(30,))\n",
        "new_embedding = Embedding(input_dim= vocab_size+1, output_dim = 300, mask_zero =True)(new_inputs)\n",
        "new_simple_rnn = SimpleRNN(50,input_shape= (300,),name ='rnn_layer')(new_embedding) #without return_sequences= True, which gives hidden_state of only the last element\n",
        "new_outputs = Dense(vocab_size+1,activation= 'softmax',name ='final_dense_layer'  )(new_simple_rnn)\n",
        "\n",
        "new_rnn_model = Model(inputs=new_inputs,outputs=new_outputs)\n",
        "\n",
        "new_rnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zhH_Ap-tTMY",
        "outputId": "c4bac1c8-a3fc-4675-c82a-a6133cc7000a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 30)]              0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 30, 300)           1500300   \n",
            "                                                                 \n",
            " rnn_layer (SimpleRNN)       (None, 50)                17550     \n",
            "                                                                 \n",
            " final_dense_layer (Dense)   (None, 5001)              255051    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,772,901\n",
            "Trainable params: 1,772,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dictionary with layers names and its weights of the 1st rnn model. which we take share with the new rnn model\n",
        "\n",
        "rnn_dic = {layer.name: layer.get_weights() for layer in rnn_model.layers} "
      ],
      "metadata": {
        "id": "RBOPYPRMwNlH"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting weights in the new rnn model, using the weights from the old rnn model\n",
        "new_rnn_model.layers[1].set_weights(rnn_dic['embedding']) # setting weights in embedding layer from previous rnn model\n",
        "new_rnn_model.layers[2].set_weights(rnn_dic['rnn_layer']) # setting weights in rnn layer from previous rnn model\n",
        "new_rnn_model.layers[3].set_weights(rnn_dic['final_dense_layer'])"
      ],
      "metadata": {
        "id": "WUnrcZl8wr3I"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6SZRqo9izNp4",
        "outputId": "6645a679-c68c-4fa6-c98b-bf47f51d5d4a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text last_word  \\\n",
              "0  <s> When you make changes please always check ...   working   \n",
              "1                              <s> I found them very   similar   \n",
              "2  <s> Give some overview of what the exercises a...     there   \n",
              "3                              <s> Honestly I do not  remember   \n",
              "4                              <s> Can you check the     video   \n",
              "\n",
              "                                         text_as_seq y_last_word  \n",
              "0  [1, 1064, 261, 24, 1319, 695, 109, 1004, 324, ...       [708]  \n",
              "1                            [1, 49, 168, 193, 1580]       [676]  \n",
              "2  [1, 115, 1250, 533, 532, 9, 828, 86, 858, 1431...       [189]  \n",
              "3                            [1, 1295, 49, 517, 316]       [314]  \n",
              "4                            [1, 2155, 261, 1004, 9]       [321]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-051c1f5c-93d6-4f67-af48-96c671da1427\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>last_word</th>\n",
              "      <th>text_as_seq</th>\n",
              "      <th>y_last_word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt; When you make changes please always check ...</td>\n",
              "      <td>working</td>\n",
              "      <td>[1, 1064, 261, 24, 1319, 695, 109, 1004, 324, ...</td>\n",
              "      <td>[708]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;s&gt; I found them very</td>\n",
              "      <td>similar</td>\n",
              "      <td>[1, 49, 168, 193, 1580]</td>\n",
              "      <td>[676]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;s&gt; Give some overview of what the exercises a...</td>\n",
              "      <td>there</td>\n",
              "      <td>[1, 115, 1250, 533, 532, 9, 828, 86, 858, 1431...</td>\n",
              "      <td>[189]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;s&gt; Honestly I do not</td>\n",
              "      <td>remember</td>\n",
              "      <td>[1, 1295, 49, 517, 316]</td>\n",
              "      <td>[314]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;s&gt; Can you check the</td>\n",
              "      <td>video</td>\n",
              "      <td>[1, 2155, 261, 1004, 9]</td>\n",
              "      <td>[321]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-051c1f5c-93d6-4f67-af48-96c671da1427')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-051c1f5c-93d6-4f67-af48-96c671da1427 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-051c1f5c-93d6-4f67-af48-96c671da1427');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RC5P3fqHXkj"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "**2.4.3** - Choose any sentence from the list of Prof. Protopapas's texts to predict the next word. Input this to the RNN model built for prediction and print the predicted word. Try this out with multiple sentences.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We will predict the last word of every sentences in the PP_test. We will be adding that to the dataframe along with the actucal last word, so that we can compare the predicted and actual last word**"
      ],
      "metadata": {
        "id": "BPAip18zQ7xP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating predictions from the test set for all the sentences\n",
        "predictions = new_rnn_model.predict(X_pred_padded)\n",
        "predictions.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e83f851b-2b30-4105-c689-f1dd73e9153f",
        "id": "_mjZSB9KQ0Uk"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35, 5001)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_token = tokenizer_tf.word_index"
      ],
      "metadata": {
        "id": "5ERI9stpQ0Uk"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_to_word = {j:i for i,j in word_to_token.items() }"
      ],
      "metadata": {
        "id": "q6ImLHhDQ0Ul"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the predicted last word for each of the sentences\n",
        "predicted_words = []\n",
        "\n",
        "for pred in predictions:\n",
        "  idx = np.argmax(pred)\n",
        "  word = token_to_word[idx]\n",
        "  predicted_words.append(word)\n"
      ],
      "metadata": {
        "id": "IC-OedY-Q0Ul"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred['predicted_word'] = predicted_words"
      ],
      "metadata": {
        "id": "cFS_J_IFQ0Ul"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here we have predicted the last word for every sentence, with the help of dataframe we can see the acutual last word and predicted last word**"
      ],
      "metadata": {
        "id": "aOsliiK7Ecz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred.head(33)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "116c4ce0-b6ab-4c79-c42f-74c484266fa9",
        "id": "tZx3qUErQ0Ul"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Text last_word  \\\n",
              "0   <s> When you make changes please always check ...   working   \n",
              "1                               <s> I found them very   similar   \n",
              "2   <s> Give some overview of what the exercises a...     there   \n",
              "3                               <s> Honestly I do not  remember   \n",
              "4                               <s> Can you check the     video   \n",
              "5                               <s> A&A when you have      time   \n",
              "6      <s> otherwise we will need to start working on        it   \n",
              "7   <s> I do believe these students will know CNNs...       end   \n",
              "8                                        <s> They are     ready   \n",
              "9                 <s> today I have as much as you can    handle   \n",
              "10                              <s> Almost done until      then   \n",
              "11                          <s> ok the video is super      cool   \n",
              "12                                 <s> this is for me       fun   \n",
              "13                                       <s> not much      time   \n",
              "14                                       <s> For main    course   \n",
              "15                                  <s> time to think        of   \n",
              "16                            <s> Could you share the    slides   \n",
              "17                          <s> Or we should write it      here   \n",
              "18                <s> FYI the meeting at 3pm has been     moved   \n",
              "19                                     <s> Hey ski is    closed   \n",
              "20                                       <s> V we can     start   \n",
              "21                                    <s> N just told        me   \n",
              "22                      <s> let's do this if you have      time   \n",
              "23                                       <s> Kids two    things   \n",
              "24                                      <s> about the  schedule   \n",
              "25                                         <s> to the  calendar   \n",
              "26            <s> I pushed very hard for him to start       now   \n",
              "27                                          <s> To be     frank   \n",
              "28                 <s> It is not urgent just catching        up   \n",
              "29                                       <s> here she        is   \n",
              "30                                <s> I will do it in     class   \n",
              "31                               <s> when I looked at        it   \n",
              "32                    <s> I can not exactly figure it       out   \n",
              "\n",
              "                                          text_as_seq y_last_word  \\\n",
              "0   [1, 1064, 261, 24, 1319, 695, 109, 1004, 324, ...       [708]   \n",
              "1                             [1, 49, 168, 193, 1580]       [676]   \n",
              "2   [1, 115, 1250, 533, 532, 9, 828, 86, 858, 1431...       [189]   \n",
              "3                             [1, 1295, 49, 517, 316]       [314]   \n",
              "4                             [1, 2155, 261, 1004, 9]       [321]   \n",
              "5                                [1, 1064, 261, 1676]        [12]   \n",
              "6       [1, 887, 1309, 2109, 299, 455, 302, 708, 231]        [16]   \n",
              "7   [1, 49, 517, 191, 3265, 1320, 2109, 46, 1580, ...        [54]   \n",
              "8                                      [1, 1431, 828]      [1491]   \n",
              "9         [1, 528, 49, 1676, 301, 17, 301, 261, 2155]      [2437]   \n",
              "10                                      [1, 126, 151]       [480]   \n",
              "11                        [1, 609, 9, 321, 174, 1450]       [710]   \n",
              "12                             [1, 53, 174, 409, 169]       [196]   \n",
              "13                                       [1, 316, 17]        [12]   \n",
              "14                                      [1, 409, 202]       [175]   \n",
              "15                                   [1, 12, 455, 32]       [533]   \n",
              "16                              [1, 30, 261, 1596, 9]          []   \n",
              "17                            [1, 599, 1309, 890, 16]       [192]   \n",
              "18                      [1, 9, 2095, 792, 3024, 2786]      [1625]   \n",
              "19                                     [1, 1353, 174]      [3623]   \n",
              "20                              [1, 3422, 1309, 2155]       [302]   \n",
              "21                               [1, 3189, 1838, 508]       [169]   \n",
              "22                       [1, 517, 53, 324, 261, 1676]        [12]   \n",
              "23                                       [1, 279, 34]        [89]   \n",
              "24                                        [1, 764, 9]          []   \n",
              "25                                        [1, 455, 9]          []   \n",
              "26       [1, 49, 3332, 1580, 180, 409, 162, 455, 302]       [369]   \n",
              "27                                      [1, 455, 557]      [1059]   \n",
              "28                      [1, 16, 174, 316, 1838, 4360]       [332]   \n",
              "29                                     [1, 192, 1800]       [174]   \n",
              "30                        [1, 49, 2109, 517, 16, 165]       [737]   \n",
              "31                            [1, 1064, 49, 587, 792]        [16]   \n",
              "32                   [1, 49, 2155, 316, 470, 721, 16]       [255]   \n",
              "\n",
              "   predicted_word  \n",
              "0            </s>  \n",
              "1            good  \n",
              "2            </s>  \n",
              "3            even  \n",
              "4           story  \n",
              "5           never  \n",
              "6             the  \n",
              "7            film  \n",
              "8             its  \n",
              "9            </s>  \n",
              "10           much  \n",
              "11          movie  \n",
              "12            its  \n",
              "13         better  \n",
              "14     characters  \n",
              "15            one  \n",
              "16          story  \n",
              "17           dont  \n",
              "18          movie  \n",
              "19          movie  \n",
              "20           know  \n",
              "21           know  \n",
              "22           </s>  \n",
              "23         people  \n",
              "24           film  \n",
              "25           film  \n",
              "26         finish  \n",
              "27            its  \n",
              "28          movie  \n",
              "29           also  \n",
              "30          movie  \n",
              "31           film  \n",
              "32           dont  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-abb18b79-18e5-4bff-b9f9-e4e3b5542b18\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>last_word</th>\n",
              "      <th>text_as_seq</th>\n",
              "      <th>y_last_word</th>\n",
              "      <th>predicted_word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt; When you make changes please always check ...</td>\n",
              "      <td>working</td>\n",
              "      <td>[1, 1064, 261, 24, 1319, 695, 109, 1004, 324, ...</td>\n",
              "      <td>[708]</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;s&gt; I found them very</td>\n",
              "      <td>similar</td>\n",
              "      <td>[1, 49, 168, 193, 1580]</td>\n",
              "      <td>[676]</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;s&gt; Give some overview of what the exercises a...</td>\n",
              "      <td>there</td>\n",
              "      <td>[1, 115, 1250, 533, 532, 9, 828, 86, 858, 1431...</td>\n",
              "      <td>[189]</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;s&gt; Honestly I do not</td>\n",
              "      <td>remember</td>\n",
              "      <td>[1, 1295, 49, 517, 316]</td>\n",
              "      <td>[314]</td>\n",
              "      <td>even</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;s&gt; Can you check the</td>\n",
              "      <td>video</td>\n",
              "      <td>[1, 2155, 261, 1004, 9]</td>\n",
              "      <td>[321]</td>\n",
              "      <td>story</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>&lt;s&gt; A&amp;A when you have</td>\n",
              "      <td>time</td>\n",
              "      <td>[1, 1064, 261, 1676]</td>\n",
              "      <td>[12]</td>\n",
              "      <td>never</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>&lt;s&gt; otherwise we will need to start working on</td>\n",
              "      <td>it</td>\n",
              "      <td>[1, 887, 1309, 2109, 299, 455, 302, 708, 231]</td>\n",
              "      <td>[16]</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>&lt;s&gt; I do believe these students will know CNNs...</td>\n",
              "      <td>end</td>\n",
              "      <td>[1, 49, 517, 191, 3265, 1320, 2109, 46, 1580, ...</td>\n",
              "      <td>[54]</td>\n",
              "      <td>film</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>&lt;s&gt; They are</td>\n",
              "      <td>ready</td>\n",
              "      <td>[1, 1431, 828]</td>\n",
              "      <td>[1491]</td>\n",
              "      <td>its</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>&lt;s&gt; today I have as much as you can</td>\n",
              "      <td>handle</td>\n",
              "      <td>[1, 528, 49, 1676, 301, 17, 301, 261, 2155]</td>\n",
              "      <td>[2437]</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>&lt;s&gt; Almost done until</td>\n",
              "      <td>then</td>\n",
              "      <td>[1, 126, 151]</td>\n",
              "      <td>[480]</td>\n",
              "      <td>much</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>&lt;s&gt; ok the video is super</td>\n",
              "      <td>cool</td>\n",
              "      <td>[1, 609, 9, 321, 174, 1450]</td>\n",
              "      <td>[710]</td>\n",
              "      <td>movie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>&lt;s&gt; this is for me</td>\n",
              "      <td>fun</td>\n",
              "      <td>[1, 53, 174, 409, 169]</td>\n",
              "      <td>[196]</td>\n",
              "      <td>its</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>&lt;s&gt; not much</td>\n",
              "      <td>time</td>\n",
              "      <td>[1, 316, 17]</td>\n",
              "      <td>[12]</td>\n",
              "      <td>better</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>&lt;s&gt; For main</td>\n",
              "      <td>course</td>\n",
              "      <td>[1, 409, 202]</td>\n",
              "      <td>[175]</td>\n",
              "      <td>characters</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>&lt;s&gt; time to think</td>\n",
              "      <td>of</td>\n",
              "      <td>[1, 12, 455, 32]</td>\n",
              "      <td>[533]</td>\n",
              "      <td>one</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>&lt;s&gt; Could you share the</td>\n",
              "      <td>slides</td>\n",
              "      <td>[1, 30, 261, 1596, 9]</td>\n",
              "      <td>[]</td>\n",
              "      <td>story</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>&lt;s&gt; Or we should write it</td>\n",
              "      <td>here</td>\n",
              "      <td>[1, 599, 1309, 890, 16]</td>\n",
              "      <td>[192]</td>\n",
              "      <td>dont</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>&lt;s&gt; FYI the meeting at 3pm has been</td>\n",
              "      <td>moved</td>\n",
              "      <td>[1, 9, 2095, 792, 3024, 2786]</td>\n",
              "      <td>[1625]</td>\n",
              "      <td>movie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>&lt;s&gt; Hey ski is</td>\n",
              "      <td>closed</td>\n",
              "      <td>[1, 1353, 174]</td>\n",
              "      <td>[3623]</td>\n",
              "      <td>movie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>&lt;s&gt; V we can</td>\n",
              "      <td>start</td>\n",
              "      <td>[1, 3422, 1309, 2155]</td>\n",
              "      <td>[302]</td>\n",
              "      <td>know</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>&lt;s&gt; N just told</td>\n",
              "      <td>me</td>\n",
              "      <td>[1, 3189, 1838, 508]</td>\n",
              "      <td>[169]</td>\n",
              "      <td>know</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>&lt;s&gt; let's do this if you have</td>\n",
              "      <td>time</td>\n",
              "      <td>[1, 517, 53, 324, 261, 1676]</td>\n",
              "      <td>[12]</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>&lt;s&gt; Kids two</td>\n",
              "      <td>things</td>\n",
              "      <td>[1, 279, 34]</td>\n",
              "      <td>[89]</td>\n",
              "      <td>people</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>&lt;s&gt; about the</td>\n",
              "      <td>schedule</td>\n",
              "      <td>[1, 764, 9]</td>\n",
              "      <td>[]</td>\n",
              "      <td>film</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>&lt;s&gt; to the</td>\n",
              "      <td>calendar</td>\n",
              "      <td>[1, 455, 9]</td>\n",
              "      <td>[]</td>\n",
              "      <td>film</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>&lt;s&gt; I pushed very hard for him to start</td>\n",
              "      <td>now</td>\n",
              "      <td>[1, 49, 3332, 1580, 180, 409, 162, 455, 302]</td>\n",
              "      <td>[369]</td>\n",
              "      <td>finish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>&lt;s&gt; To be</td>\n",
              "      <td>frank</td>\n",
              "      <td>[1, 455, 557]</td>\n",
              "      <td>[1059]</td>\n",
              "      <td>its</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>&lt;s&gt; It is not urgent just catching</td>\n",
              "      <td>up</td>\n",
              "      <td>[1, 16, 174, 316, 1838, 4360]</td>\n",
              "      <td>[332]</td>\n",
              "      <td>movie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>&lt;s&gt; here she</td>\n",
              "      <td>is</td>\n",
              "      <td>[1, 192, 1800]</td>\n",
              "      <td>[174]</td>\n",
              "      <td>also</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>&lt;s&gt; I will do it in</td>\n",
              "      <td>class</td>\n",
              "      <td>[1, 49, 2109, 517, 16, 165]</td>\n",
              "      <td>[737]</td>\n",
              "      <td>movie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>&lt;s&gt; when I looked at</td>\n",
              "      <td>it</td>\n",
              "      <td>[1, 1064, 49, 587, 792]</td>\n",
              "      <td>[16]</td>\n",
              "      <td>film</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>&lt;s&gt; I can not exactly figure it</td>\n",
              "      <td>out</td>\n",
              "      <td>[1, 49, 2155, 316, 470, 721, 16]</td>\n",
              "      <td>[255]</td>\n",
              "      <td>dont</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-abb18b79-18e5-4bff-b9f9-e4e3b5542b18')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-abb18b79-18e5-4bff-b9f9-e4e3b5542b18 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-abb18b79-18e5-4bff-b9f9-e4e3b5542b18');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicting One sentence at a time**"
      ],
      "metadata": {
        "id": "9QROIxuRR_4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'predicting the next word of the second senetence- \" {df_pred.iloc[1][\"Text\"]} \"')\n",
        "# X_pred_padded[0] # predicting the next word of the first senetence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "251EVcgszR6E",
        "outputId": "c648d262-4c53-41e5-d6b0-159ba6c53039"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicting the next word of the second senetence- \" <s> I found them very \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# changinf the shape of input variable\n",
        "test_x = X_pred_padded[1].reshape(1,-1)\n",
        "test_x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8ebV_NDygBd",
        "outputId": "e091ec67-3467-4d7a-aca4-3ee7b5409c5a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'predicting the next word of the second senetence- \" {df_pred.iloc[1][\"Text\"]} \"')\n",
        "print('-----')\n",
        "preds = new_rnn_model.predict(test_x) # getting the list of probabilty\n",
        "idx = np.argmax(preds) # getting the index from the prob districution of the highest\n",
        "print(f\"the predicted next word of the second sentece is : {token_to_word[idx]}, the actual last word is : {df_pred['last_word'][0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKHht6R0x08_",
        "outputId": "1684fcd5-339c-4f99-f005-4cbd74f13bce"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicting the next word of the second senetence- \" <s> I found them very \"\n",
            "-----\n",
            "the predicted next word of the second sentece is : good, the actual last word is : working\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "appaIgaqHXkj"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "**2.4.4** - Do you notice any pattern in the predicted words? Do they seem approriate to the context of the texts as you understand it? What do you attribute this discrepency to? How can you resolve it?\n",
        "\n",
        "Answer in less than 150 words.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKGvrS06HXkj"
      },
      "source": [
        "**Type your answer here**\n",
        "\n",
        "We see that most of the predicted words to be the startig token '<s->\", the reason for that might be the vanishing gradients that we see in RNN models. The fixed weights of RNN layers will add to this. Here, we also have a comparitively small dataset.\n",
        "\n",
        "At the sametime, we also predicted some words which seems appropriate to the context. \n",
        "\n",
        "We could improve this model by solving the issue of vanishing gradients and introducing more parameter which would be a function of the input word and the previous hidden states/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uKAkAUYHXkj"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "\n",
        "### **2.5 [7 points] TRAINING AND PREDICTING WITH A DIFFERENT DATASET**\n",
        "<br />\n",
        "    \n",
        "**2.5.1** - Read the dataset `cleaned_sarcasm.csv`. This dataset has been preprocessed for you, all you need to do is tokenize, convert to sequence and pad it, similar to 2.2.1, 2.2.2 and 2.3.1.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "8eVJUn-hHXkj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1e88915e-51bd-4e9c-8f85-173dd9669f54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text\n",
              "0  you do know west teams play against west teams...\n",
              "1  they were underdogs earlier today but since gr...\n",
              "2  you dont have to you have a good build buy gam...\n",
              "3  i think a significant amount would be against ...\n",
              "4  ayy bb wassup it makes a bit more sense in con..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f55984c-e882-450c-946e-3a7a17ae5977\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>you do know west teams play against west teams...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>they were underdogs earlier today but since gr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>you dont have to you have a good build buy gam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i think a significant amount would be against ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ayy bb wassup it makes a bit more sense in con...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f55984c-e882-450c-946e-3a7a17ae5977')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f55984c-e882-450c-946e-3a7a17ae5977 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f55984c-e882-450c-946e-3a7a17ae5977');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "# Read the data\n",
        "file_path = \"https://drive.google.com/uc?id=1kHZIXEcf_t0t2GcxtafF3mL0kuoC4etf&export=download\"\n",
        "df_sarcasm = pd.read_csv(file_path)\n",
        "df_sarcasm.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Shape of new Datafame(sarcasm) {df_sarcasm.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ujxhqDCWw_Q",
        "outputId": "1d9a6757-45c7-4892-c46c-1e1a56f195ac"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of new Datafame(sarcasm) (289506, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "0RMbwMBOHXkj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "ec7a2121-8306-44bb-c7c8-cdd4e5dfb3a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  you do know west teams play against west teams...   \n",
              "1  they were underdogs earlier today but since gr...   \n",
              "2  you dont have to you have a good build buy gam...   \n",
              "3  i think a significant amount would be against ...   \n",
              "4  ayy bb wassup it makes a bit more sense in con...   \n",
              "5  because its what really bothers him and its a ...   \n",
              "6  because theyre not real human beings with actu...   \n",
              "7  tbh that giant dent was probably made by the g...   \n",
              "\n",
              "                                              tokens  \n",
              "0    [261, 517, 46, 1071, 194, 1071, 592, 2573, 133]  \n",
              "1  [1431, 739, 654, 528, 222, 116, 53, 2444, 9, 3...  \n",
              "2  [261, 29, 1676, 455, 261, 1676, 214, 8, 1784, ...  \n",
              "3  [49, 32, 214, 2387, 925, 11, 557, 2581, 2543, ...  \n",
              "4            [16, 65, 214, 134, 592, 198, 165, 1732]  \n",
              "5  [1536, 7, 532, 15, 162, 86, 7, 214, 2019, 533,...  \n",
              "6  [1536, 423, 316, 66, 317, 2908, 421, 647, 1297...  \n",
              "7           [143, 1322, 539, 127, 26, 1257, 9, 1036]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e322b607-6193-4141-a380-8d993fde64d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>you do know west teams play against west teams...</td>\n",
              "      <td>[261, 517, 46, 1071, 194, 1071, 592, 2573, 133]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>they were underdogs earlier today but since gr...</td>\n",
              "      <td>[1431, 739, 654, 528, 222, 116, 53, 2444, 9, 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>you dont have to you have a good build buy gam...</td>\n",
              "      <td>[261, 29, 1676, 455, 261, 1676, 214, 8, 1784, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i think a significant amount would be against ...</td>\n",
              "      <td>[49, 32, 214, 2387, 925, 11, 557, 2581, 2543, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ayy bb wassup it makes a bit more sense in con...</td>\n",
              "      <td>[16, 65, 214, 134, 592, 198, 165, 1732]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>because its what really bothers him and its a ...</td>\n",
              "      <td>[1536, 7, 532, 15, 162, 86, 7, 214, 2019, 533,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>because theyre not real human beings with actu...</td>\n",
              "      <td>[1536, 423, 316, 66, 317, 2908, 421, 647, 1297...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>tbh that giant dent was probably made by the g...</td>\n",
              "      <td>[143, 1322, 539, 127, 26, 1257, 9, 1036]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e322b607-6193-4141-a380-8d993fde64d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e322b607-6193-4141-a380-8d993fde64d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e322b607-6193-4141-a380-8d993fde64d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "# Tokenize the data\n",
        "df_sarcasm['tokens'] = tokenizer_tf.texts_to_sequences(df_sarcasm['text'])\n",
        "df_sarcasm.head(8)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = tf.keras.preprocessing.sequence.pad_sequences(df_sarcasm['tokens'],maxlen=31,padding='post')\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2dhMsFJVepk",
        "outputId": "169be26d-af20-49b4-a793-85b1e7081736"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(289506, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sarcasm['text'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9OF-7G3JXL_Q",
        "outputId": "2039709f-e647-4812-f596-b7503933b535"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'you do know west teams play against west teams more than east teams right'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYyaRc4qW_qC",
        "outputId": "304cbfac-d438-4097-acc6-5338344d876a"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 261,  517,   46, 1071,  194, 1071,  592, 2573,  133,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating X and Y \n",
        "X = data[:,0:30]\n",
        "y = data[:,1:31]"
      ],
      "metadata": {
        "id": "wdA8qVT8XyMp"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'example of train_x {X[0]}')\n",
        "print(f'example of train_y {y[0]}')\n",
        "# we can see that the elements in y, is the next element in X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og_WucREYEpn",
        "outputId": "38af2ebe-dbf6-432c-f3dc-dc4a7e38cbbb"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example of train_x [ 261  517   46 1071  194 1071  592 2573  133    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "example of train_y [ 517   46 1071  194 1071  592 2573  133    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDo-fIiXHXkk"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "**2.5.2** - Train your RNN model with this data and plot the train and validation trace plot. This part is similar to 2.3.2, 2.3.3 and 2.3.4.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "41SMwk6BHXkk"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "inputs = Input(shape=(30,))\n",
        "embedding = Embedding(input_dim= vocab_size+1,output_dim= 300,mask_zero =True)(inputs)\n",
        "rnn_layer = SimpleRNN(50,input_shape=(300,30), return_sequences=True)(embedding) # we can have the input_shape as (300,) as well - maybe (300,None) might also work\n",
        "outputs = Dense(vocab_size+1,activation='softmax')(rnn_layer)\n",
        "rnn_model_sarcasm = Model(inputs=inputs,outputs=outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model_sarcasm.compile(loss= tf.keras.losses.SparseCategoricalCrossentropy(),optimizer='adam',\n",
        "                            metrics= ['accuracy'])"
      ],
      "metadata": {
        "id": "N7HdpRP4cEi-"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_sarcasm= rnn_model_sarcasm.fit(X,y,epochs=20,validation_split=0.2,batch_size=512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gioj29QQgo_r",
        "outputId": "078eded0-8c3e-414a-d37c-6ac03b597e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "453/453 [==============================] - 42s 90ms/step - loss: 2.6749 - accuracy: 0.0693 - val_loss: 2.6890 - val_accuracy: 0.0727\n",
            "Epoch 2/20\n",
            "453/453 [==============================] - 41s 91ms/step - loss: 2.4514 - accuracy: 0.0992 - val_loss: 2.5156 - val_accuracy: 0.1172\n",
            "Epoch 3/20\n",
            "453/453 [==============================] - 40s 87ms/step - loss: 2.3135 - accuracy: 0.1392 - val_loss: 2.4150 - val_accuracy: 0.1385\n",
            "Epoch 4/20\n",
            "453/453 [==============================] - 39s 87ms/step - loss: 2.2434 - accuracy: 0.1521 - val_loss: 2.3657 - val_accuracy: 0.1513\n",
            "Epoch 5/20\n",
            "453/453 [==============================] - 39s 87ms/step - loss: 2.1958 - accuracy: 0.1665 - val_loss: 2.3296 - val_accuracy: 0.1618\n",
            "Epoch 6/20\n",
            "453/453 [==============================] - 40s 87ms/step - loss: 2.1681 - accuracy: 0.1731 - val_loss: 2.3114 - val_accuracy: 0.1646\n",
            "Epoch 7/20\n",
            "453/453 [==============================] - 40s 87ms/step - loss: 2.1509 - accuracy: 0.1758 - val_loss: 2.2992 - val_accuracy: 0.1667\n",
            "Epoch 8/20\n",
            "453/453 [==============================] - 39s 87ms/step - loss: 2.1378 - accuracy: 0.1778 - val_loss: 2.2890 - val_accuracy: 0.1682\n",
            "Epoch 9/20\n",
            "453/453 [==============================] - 39s 87ms/step - loss: 2.1276 - accuracy: 0.1794 - val_loss: 2.2823 - val_accuracy: 0.1691\n",
            "Epoch 10/20\n",
            "453/453 [==============================] - 39s 87ms/step - loss: 2.1191 - accuracy: 0.1805 - val_loss: 2.2756 - val_accuracy: 0.1704\n",
            "Epoch 11/20\n",
            "453/453 [==============================] - 39s 87ms/step - loss: 2.1119 - accuracy: 0.1816 - val_loss: 2.2713 - val_accuracy: 0.1711\n",
            "Epoch 12/20\n",
            "453/453 [==============================] - 39s 87ms/step - loss: 2.1058 - accuracy: 0.1827 - val_loss: 2.2666 - val_accuracy: 0.1723\n",
            "Epoch 13/20\n",
            "453/453 [==============================] - 39s 87ms/step - loss: 2.1004 - accuracy: 0.1836 - val_loss: 2.2629 - val_accuracy: 0.1729\n",
            "Epoch 14/20\n",
            "453/453 [==============================] - 39s 87ms/step - loss: 2.0955 - accuracy: 0.1844 - val_loss: 2.2597 - val_accuracy: 0.1738\n",
            "Epoch 15/20\n",
            "453/453 [==============================] - 39s 87ms/step - loss: 2.0913 - accuracy: 0.1851 - val_loss: 2.2571 - val_accuracy: 0.1739\n",
            "Epoch 16/20\n",
            "453/453 [==============================] - 39s 86ms/step - loss: 2.0875 - accuracy: 0.1856 - val_loss: 2.2547 - val_accuracy: 0.1742\n",
            "Epoch 17/20\n",
            "453/453 [==============================] - 39s 87ms/step - loss: 2.0840 - accuracy: 0.1861 - val_loss: 2.2527 - val_accuracy: 0.1747\n",
            "Epoch 18/20\n",
            "453/453 [==============================] - 39s 86ms/step - loss: 2.0811 - accuracy: 0.1865 - val_loss: 2.2521 - val_accuracy: 0.1740\n",
            "Epoch 19/20\n",
            "453/453 [==============================] - 40s 88ms/step - loss: 2.0783 - accuracy: 0.1869 - val_loss: 2.2487 - val_accuracy: 0.1752\n",
            "Epoch 20/20\n",
            "163/453 [=========>....................] - ETA: 23s - loss: 2.0762 - accuracy: 0.1876"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_sarcasm= rnn_model_sarcasm.fit(X,y,epochs=20,validation_split=0.2,batch_size=512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKKurLYNcb9d",
        "outputId": "f2769af1-a50b-4d15-8b3f-fc076e9e1b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "453/453 [==============================] - 39s 85ms/step - loss: 2.5142 - accuracy: 0.0892 - val_loss: 2.5450 - val_accuracy: 0.1027\n",
            "Epoch 2/20\n",
            "453/453 [==============================] - 38s 84ms/step - loss: 2.3282 - accuracy: 0.1342 - val_loss: 2.4194 - val_accuracy: 0.1403\n",
            "Epoch 3/20\n",
            "453/453 [==============================] - 38s 83ms/step - loss: 2.2432 - accuracy: 0.1547 - val_loss: 2.3632 - val_accuracy: 0.1556\n",
            "Epoch 4/20\n",
            "453/453 [==============================] - 37s 83ms/step - loss: 2.1964 - accuracy: 0.1674 - val_loss: 2.3322 - val_accuracy: 0.1605\n",
            "Epoch 5/20\n",
            "453/453 [==============================] - 38s 83ms/step - loss: 2.1707 - accuracy: 0.1719 - val_loss: 2.3154 - val_accuracy: 0.1633\n",
            "Epoch 6/20\n",
            "453/453 [==============================] - 38s 83ms/step - loss: 2.1533 - accuracy: 0.1749 - val_loss: 2.3015 - val_accuracy: 0.1657\n",
            "Epoch 7/20\n",
            "453/453 [==============================] - 38s 85ms/step - loss: 2.1401 - accuracy: 0.1772 - val_loss: 2.2915 - val_accuracy: 0.1673\n",
            "Epoch 8/20\n",
            "453/453 [==============================] - 37s 83ms/step - loss: 2.1295 - accuracy: 0.1789 - val_loss: 2.2837 - val_accuracy: 0.1686\n",
            "Epoch 9/20\n",
            "453/453 [==============================] - 37s 83ms/step - loss: 2.1209 - accuracy: 0.1802 - val_loss: 2.2772 - val_accuracy: 0.1698\n",
            "Epoch 10/20\n",
            "453/453 [==============================] - 37s 82ms/step - loss: 2.1138 - accuracy: 0.1815 - val_loss: 2.2726 - val_accuracy: 0.1703\n",
            "Epoch 11/20\n",
            "453/453 [==============================] - 37s 82ms/step - loss: 2.1079 - accuracy: 0.1822 - val_loss: 2.2683 - val_accuracy: 0.1714\n",
            "Epoch 12/20\n",
            "453/453 [==============================] - 38s 83ms/step - loss: 2.1027 - accuracy: 0.1832 - val_loss: 2.2651 - val_accuracy: 0.1723\n",
            "Epoch 13/20\n",
            "453/453 [==============================] - 38s 83ms/step - loss: 2.0982 - accuracy: 0.1839 - val_loss: 2.2619 - val_accuracy: 0.1722\n",
            "Epoch 14/20\n",
            "453/453 [==============================] - 38s 83ms/step - loss: 2.0940 - accuracy: 0.1845 - val_loss: 2.2595 - val_accuracy: 0.1728\n",
            "Epoch 15/20\n",
            "453/453 [==============================] - 38s 83ms/step - loss: 2.0903 - accuracy: 0.1851 - val_loss: 2.2574 - val_accuracy: 0.1731\n",
            "Epoch 16/20\n",
            "453/453 [==============================] - 38s 84ms/step - loss: 2.0869 - accuracy: 0.1857 - val_loss: 2.2546 - val_accuracy: 0.1742\n",
            "Epoch 17/20\n",
            "453/453 [==============================] - 38s 84ms/step - loss: 2.0838 - accuracy: 0.1863 - val_loss: 2.2527 - val_accuracy: 0.1747\n",
            "Epoch 18/20\n",
            "453/453 [==============================] - 38s 83ms/step - loss: 2.0810 - accuracy: 0.1868 - val_loss: 2.2508 - val_accuracy: 0.1748\n",
            "Epoch 19/20\n",
            "453/453 [==============================] - 38s 85ms/step - loss: 2.0783 - accuracy: 0.1872 - val_loss: 2.2494 - val_accuracy: 0.1754\n",
            "Epoch 20/20\n",
            "453/453 [==============================] - 39s 85ms/step - loss: 2.0759 - accuracy: 0.1875 - val_loss: 2.2476 - val_accuracy: 0.1755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(13,10))\n",
        "\n",
        "plt.plot(list(range(no_of_epochs)), history_sarcasm.history['loss'], label='Train loss')\n",
        "plt.plot(list(range(no_of_epochs)), history_sarcasm.history['val_loss'], label='Val loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend()\n",
        "plt.ylabel('loss')\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "Vux4DtDAGbqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(13,10))\n",
        "\n",
        "plt.plot(list(range(no_of_epochs)), history_sarcasm.history['loss'], label='Train loss')\n",
        "plt.plot(list(range(no_of_epochs)), history_sarcasm.history['val_loss'], label='Val loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend()\n",
        "plt.ylabel('loss')\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "ZGqQLa5UdZJF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "a1bfbb4c-07e5-40d7-8175-40433c014ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 936x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpqpMMQTHXkk"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "**2.5.3** - Repeat 2.4.1, 2.4.2 and 2.4.3 with the RNN model trained using the new dataset.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_inputs = Input(shape=(30,))\n",
        "new_embedding = Embedding(input_dim= vocab_size+1, output_dim = 300, mask_zero =True)(new_inputs)\n",
        "new_simple_rnn = SimpleRNN(50,input_shape= (300,),name ='rnn_layer')(new_embedding) #without return_sequences= True, which gives hidden_state of only the last element\n",
        "new_outputs = Dense(vocab_size+1,activation= 'softmax',name ='final_dense_layer'  )(new_simple_rnn)\n",
        "\n",
        "new_rnn_model = Model(inputs=new_inputs,outputs=new_outputs)\n",
        "\n",
        "new_rnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddBPtnisefmK",
        "outputId": "2294f4fa-67f3-4842-cad9-0e03536a55ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 30)]              0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 30, 300)           1500300   \n",
            "                                                                 \n",
            " rnn_layer (SimpleRNN)       (None, 50)                17550     \n",
            "                                                                 \n",
            " final_dense_layer (Dense)   (None, 5001)              255051    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,772,901\n",
            "Trainable params: 1,772,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_sarcasm_dic = {layer.name: layer.get_weights() for layer in rnn_model_sarcasm.layers} "
      ],
      "metadata": {
        "id": "nhsJhTQJe3AQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting weights in the new rnn model\n",
        "new_rnn_model.layers[1].set_weights(rnn_sarcasm_dic['embedding_1']) # setting weights in embedding layer from previous rnn model\n",
        "new_rnn_model.layers[2].set_weights(rnn_sarcasm_dic['simple_rnn']) # setting weights in rnn layer from previous rnn model\n",
        "new_rnn_model.layers[3].set_weights(rnn_sarcasm_dic['dense'])"
      ],
      "metadata": {
        "id": "saVtJ8hEe25Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = new_rnn_model.predict(X_pred_padded)\n",
        "predictions.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1UbIQtffQSm",
        "outputId": "59fc3e78-4e7e-44e9-8781-ddf01f0689d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35, 5001)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting tokens back to word\n",
        "word_to_token = tokenizer_tf.word_index\n",
        "\n",
        "token_to_word = {j:i for i,j in word_to_token.items() }\n",
        "token_to_word[0] = '</s>'"
      ],
      "metadata": {
        "id": "KalznMQUfSbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the predicted last word for each of the sentences\n",
        "predicted_words = []\n",
        "\n",
        "for pred in predictions:\n",
        "  idx = np.argmax(pred)\n",
        "  word = token_to_word[idx]\n",
        "  predicted_words.append(word)\n",
        "\n"
      ],
      "metadata": {
        "id": "jZ_d5quAfZeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred['predicted_word_sarcasm'] = predicted_words"
      ],
      "metadata": {
        "id": "JAcEdq90fhif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        },
        "id": "bCkaLFXTfoFX",
        "outputId": "413c0700-6ff5-46ac-ad00-64683a186936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Text last_word  \\\n",
              "0   <s> When you make changes please always check ...   working   \n",
              "1                               <s> I found them very   similar   \n",
              "2   <s> Give some overview of what the exercises a...     there   \n",
              "3                               <s> Honestly I do not  remember   \n",
              "4                               <s> Can you check the     video   \n",
              "5                               <s> A&A when you have      time   \n",
              "6      <s> otherwise we will need to start working on        it   \n",
              "7   <s> I do believe these students will know CNNs...       end   \n",
              "8                                        <s> They are     ready   \n",
              "9                 <s> today I have as much as you can    handle   \n",
              "10                              <s> Almost done until      then   \n",
              "11                          <s> ok the video is super      cool   \n",
              "12                                 <s> this is for me       fun   \n",
              "13                                       <s> not much      time   \n",
              "14                                       <s> For main    course   \n",
              "15                                  <s> time to think        of   \n",
              "16                            <s> Could you share the    slides   \n",
              "17                          <s> Or we should write it      here   \n",
              "18                <s> FYI the meeting at 3pm has been     moved   \n",
              "19                                     <s> Hey ski is    closed   \n",
              "\n",
              "                                          text_as_seq y_last_word  \\\n",
              "0   [1, 1064, 261, 24, 1319, 695, 109, 1004, 324, ...       [708]   \n",
              "1                             [1, 49, 168, 193, 1580]       [676]   \n",
              "2   [1, 115, 1250, 533, 532, 9, 828, 86, 858, 1431...       [189]   \n",
              "3                             [1, 1295, 49, 517, 316]       [314]   \n",
              "4                             [1, 2155, 261, 1004, 9]       [321]   \n",
              "5                                [1, 1064, 261, 1676]        [12]   \n",
              "6       [1, 887, 1309, 2109, 299, 455, 302, 708, 231]        [16]   \n",
              "7   [1, 49, 517, 191, 3265, 1320, 2109, 46, 1580, ...        [54]   \n",
              "8                                      [1, 1431, 828]      [1491]   \n",
              "9         [1, 528, 49, 1676, 301, 17, 301, 261, 2155]      [2437]   \n",
              "10                                      [1, 126, 151]       [480]   \n",
              "11                        [1, 609, 9, 321, 174, 1450]       [710]   \n",
              "12                             [1, 53, 174, 409, 169]       [196]   \n",
              "13                                       [1, 316, 17]        [12]   \n",
              "14                                      [1, 409, 202]       [175]   \n",
              "15                                   [1, 12, 455, 32]       [533]   \n",
              "16                              [1, 30, 261, 1596, 9]          []   \n",
              "17                            [1, 599, 1309, 890, 16]       [192]   \n",
              "18                      [1, 9, 2095, 792, 3024, 2786]      [1625]   \n",
              "19                                     [1, 1353, 174]      [3623]   \n",
              "\n",
              "   predicted_word predicted_word_sarcasm  \n",
              "0            </s>                      a  \n",
              "1            good                   much  \n",
              "2            </s>                   </s>  \n",
              "3            like                   know  \n",
              "4           story                     to  \n",
              "5            seen                      a  \n",
              "6             its                    the  \n",
              "7            film                   </s>  \n",
              "8            dont                    the  \n",
              "9            </s>                    get  \n",
              "10           film                   that  \n",
              "11           film                   easy  \n",
              "12            its                    but  \n",
              "13         better                     as  \n",
              "14      character                 reason  \n",
              "15           film                     of  \n",
              "16           film                   same  \n",
              "17            its                     in  \n",
              "18            one                    the  \n",
              "19           like                      a  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd1c0e9e-ea01-4097-857e-8e5ab2d13866\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>last_word</th>\n",
              "      <th>text_as_seq</th>\n",
              "      <th>y_last_word</th>\n",
              "      <th>predicted_word</th>\n",
              "      <th>predicted_word_sarcasm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt; When you make changes please always check ...</td>\n",
              "      <td>working</td>\n",
              "      <td>[1, 1064, 261, 24, 1319, 695, 109, 1004, 324, ...</td>\n",
              "      <td>[708]</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;s&gt; I found them very</td>\n",
              "      <td>similar</td>\n",
              "      <td>[1, 49, 168, 193, 1580]</td>\n",
              "      <td>[676]</td>\n",
              "      <td>good</td>\n",
              "      <td>much</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;s&gt; Give some overview of what the exercises a...</td>\n",
              "      <td>there</td>\n",
              "      <td>[1, 115, 1250, 533, 532, 9, 828, 86, 858, 1431...</td>\n",
              "      <td>[189]</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;s&gt; Honestly I do not</td>\n",
              "      <td>remember</td>\n",
              "      <td>[1, 1295, 49, 517, 316]</td>\n",
              "      <td>[314]</td>\n",
              "      <td>like</td>\n",
              "      <td>know</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;s&gt; Can you check the</td>\n",
              "      <td>video</td>\n",
              "      <td>[1, 2155, 261, 1004, 9]</td>\n",
              "      <td>[321]</td>\n",
              "      <td>story</td>\n",
              "      <td>to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>&lt;s&gt; A&amp;A when you have</td>\n",
              "      <td>time</td>\n",
              "      <td>[1, 1064, 261, 1676]</td>\n",
              "      <td>[12]</td>\n",
              "      <td>seen</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>&lt;s&gt; otherwise we will need to start working on</td>\n",
              "      <td>it</td>\n",
              "      <td>[1, 887, 1309, 2109, 299, 455, 302, 708, 231]</td>\n",
              "      <td>[16]</td>\n",
              "      <td>its</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>&lt;s&gt; I do believe these students will know CNNs...</td>\n",
              "      <td>end</td>\n",
              "      <td>[1, 49, 517, 191, 3265, 1320, 2109, 46, 1580, ...</td>\n",
              "      <td>[54]</td>\n",
              "      <td>film</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>&lt;s&gt; They are</td>\n",
              "      <td>ready</td>\n",
              "      <td>[1, 1431, 828]</td>\n",
              "      <td>[1491]</td>\n",
              "      <td>dont</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>&lt;s&gt; today I have as much as you can</td>\n",
              "      <td>handle</td>\n",
              "      <td>[1, 528, 49, 1676, 301, 17, 301, 261, 2155]</td>\n",
              "      <td>[2437]</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "      <td>get</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>&lt;s&gt; Almost done until</td>\n",
              "      <td>then</td>\n",
              "      <td>[1, 126, 151]</td>\n",
              "      <td>[480]</td>\n",
              "      <td>film</td>\n",
              "      <td>that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>&lt;s&gt; ok the video is super</td>\n",
              "      <td>cool</td>\n",
              "      <td>[1, 609, 9, 321, 174, 1450]</td>\n",
              "      <td>[710]</td>\n",
              "      <td>film</td>\n",
              "      <td>easy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>&lt;s&gt; this is for me</td>\n",
              "      <td>fun</td>\n",
              "      <td>[1, 53, 174, 409, 169]</td>\n",
              "      <td>[196]</td>\n",
              "      <td>its</td>\n",
              "      <td>but</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>&lt;s&gt; not much</td>\n",
              "      <td>time</td>\n",
              "      <td>[1, 316, 17]</td>\n",
              "      <td>[12]</td>\n",
              "      <td>better</td>\n",
              "      <td>as</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>&lt;s&gt; For main</td>\n",
              "      <td>course</td>\n",
              "      <td>[1, 409, 202]</td>\n",
              "      <td>[175]</td>\n",
              "      <td>character</td>\n",
              "      <td>reason</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>&lt;s&gt; time to think</td>\n",
              "      <td>of</td>\n",
              "      <td>[1, 12, 455, 32]</td>\n",
              "      <td>[533]</td>\n",
              "      <td>film</td>\n",
              "      <td>of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>&lt;s&gt; Could you share the</td>\n",
              "      <td>slides</td>\n",
              "      <td>[1, 30, 261, 1596, 9]</td>\n",
              "      <td>[]</td>\n",
              "      <td>film</td>\n",
              "      <td>same</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>&lt;s&gt; Or we should write it</td>\n",
              "      <td>here</td>\n",
              "      <td>[1, 599, 1309, 890, 16]</td>\n",
              "      <td>[192]</td>\n",
              "      <td>its</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>&lt;s&gt; FYI the meeting at 3pm has been</td>\n",
              "      <td>moved</td>\n",
              "      <td>[1, 9, 2095, 792, 3024, 2786]</td>\n",
              "      <td>[1625]</td>\n",
              "      <td>one</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>&lt;s&gt; Hey ski is</td>\n",
              "      <td>closed</td>\n",
              "      <td>[1, 1353, 174]</td>\n",
              "      <td>[3623]</td>\n",
              "      <td>like</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd1c0e9e-ea01-4097-857e-8e5ab2d13866')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd1c0e9e-ea01-4097-857e-8e5ab2d13866 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd1c0e9e-ea01-4097-857e-8e5ab2d13866');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2pfM2rZHXkk"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "**2.5.4** - How do the results with the new dataset compare to the previous ones? Why do you think so? \n",
        "\n",
        "Answer in less than 100 words.\n",
        "    \n",
        "Since the dataset was longer, we have better result with the new model trained on the df_sarcasm data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4LSts_RHXkk"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\">\n",
        "\n",
        "\n",
        "### **2.6 [4 points] COMPLETING THE SENTENCE**\n",
        "<br />\n",
        "\n",
        "**2.6.1** Until now we have predicted a single word for a given sentence. However, what if he meant more than one word when he typed in `...`\n",
        "\n",
        "We will now predict multiple words for each input sentence. To do this we will first predict one word, append this word to the input text and then predict once more with the updated input. Continue doing this to predict 5 words or until the end token `</s>` (whichever comes first). \n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- first we will have a sentence\n",
        "- we will post pad to length =30\n",
        "- chnage the shape so that it will go as input to the model.\n",
        "- once we get the output add the word into the string, and repeat the process from start, till we do this 5 times or its predicts stops,"
      ],
      "metadata": {
        "id": "p98iY354Sh57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "final_sentence = []\n",
        "def input_sentence(sentence):\n",
        "  predicted_word = ' '\n",
        "  count=0\n",
        "\n",
        "  while True:\n",
        "      if (count >= 5) or predicted_word == '</s>':\n",
        "        break\n",
        "      count +=1\n",
        "      # print(sentence)\n",
        "      input_string = [sentence]\n",
        "\n",
        "      input_as_tokens= tokenizer_tf.texts_to_sequences(input_string)\n",
        "\n",
        "      input_array = tf.keras.preprocessing.sequence.pad_sequences(input_as_tokens,maxlen=30,padding='post')\n",
        "\n",
        "      preds = new_rnn_model.predict(input_array)\n",
        "\n",
        "      idx = np.argmax(preds)\n",
        "      predicted_word = token_to_word[idx]\n",
        "      # print(predicted_word)\n",
        "\n",
        "\n",
        "\n",
        "      sentence = sentence+ ' ' + predicted_word\n",
        "\n",
        "\n",
        "  return sentence\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "graclyZ9mlvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_string = 'this is one of'"
      ],
      "metadata": {
        "id": "Se_A5FowXUdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'For the input sentence: \"{input_string}\", the predicted output sentence is \"{input_sentence(input_string)}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVyvVUteXUwg",
        "outputId": "b344af79-553b-4896-d822-57b3541bbef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For the input sentence: \"this is one of\", the predicted output sentence is \"this is one of course film would like it\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fp3yBL-kmQXO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "AI3_HW1_Language_Modeling.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}